Epoch 0: loss 16.129381063387665
Epoch 1: loss 16.129384764515233
Epoch 2: loss 16.129386544292423
Epoch 3: loss 16.129383436423918
Epoch 4: loss 16.129383807470127
Epoch 5: loss 16.129387414993445
Epoch 6: loss 16.12938087125263
Epoch 7: loss 16.12937812587371
Epoch 8: loss 16.129385018880242
Epoch 9: loss 16.129381997355825
Epoch 10: loss 16.1293793964023
Epoch 11: loss 16.129384604273056
Epoch 12: loss 16.129381157251206
Epoch 13: loss 16.129378521034027
Epoch 14: loss 16.12938766883987
Epoch 15: loss 16.12939497334209
Epoch 16: loss 16.129383180762453
Epoch 17: loss 16.129393291317815
Epoch 18: loss 16.12938620902845
Epoch 19: loss 16.129386562702123
-----------Time: 0:01:20.849174, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1e-15, embedding_dim: 20, rmse: 4.017219066619873-------------


Epoch 0: loss 16.129205321021026
Epoch 1: loss 16.129205983510932
Epoch 2: loss 16.129210258191407
Epoch 3: loss 16.129213603311676
Epoch 4: loss 16.12920957573605
Epoch 5: loss 16.129204989387134
Epoch 6: loss 16.12921046432819
Epoch 7: loss 16.129209705900408
Epoch 8: loss 16.129205875127067
Epoch 9: loss 16.12920335948046
Epoch 10: loss 16.12920754522393
Epoch 11: loss 16.12920530675999
Epoch 12: loss 16.129210634423444
Epoch 13: loss 16.12920069111113
Epoch 14: loss 16.129199662760847
Epoch 15: loss 16.129204937528826
Epoch 16: loss 16.12920369967097
Epoch 17: loss 16.129208910653226
Epoch 18: loss 16.12921203667214
Epoch 19: loss 16.129203931736907
-----------Time: 0:01:32.940739, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1e-15, embedding_dim: 50, rmse: 4.017187595367432-------------


Epoch 0: loss 16.12916137188138
Epoch 1: loss 16.129168088569664
Epoch 2: loss 16.12917376368379
Epoch 3: loss 16.12916735840466
Epoch 4: loss 16.129172683215906
Epoch 5: loss 16.129168800324962
Epoch 6: loss 16.12917095788994
Epoch 7: loss 16.129163895306736
Epoch 8: loss 16.129167121152893
Epoch 9: loss 16.129166371541025
Epoch 10: loss 16.129175102665346
Epoch 11: loss 16.12916931683373
Epoch 12: loss 16.129168307411728
Epoch 13: loss 16.129170600845477
Epoch 14: loss 16.12916716367671
Epoch 15: loss 16.12917304518691
Epoch 16: loss 16.12916667024489
Epoch 17: loss 16.129166149068876
Epoch 18: loss 16.12916491924906
Epoch 19: loss 16.12916588511008
-----------Time: 0:02:01.652500, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1e-15, embedding_dim: 100, rmse: 4.017191410064697-------------


Epoch 0: loss 16.129176518915788
Epoch 1: loss 16.12917303222233
Epoch 2: loss 16.129171047345526
Epoch 3: loss 16.12917160897102
Epoch 4: loss 16.129175354956026
Epoch 5: loss 16.12917257846212
Epoch 6: loss 16.129167675518225
Epoch 7: loss 16.12917382228368
Epoch 8: loss 16.129170927812122
Epoch 9: loss 16.129183333875563
Epoch 10: loss 16.129178395668017
Epoch 11: loss 16.129171035677405
Epoch 12: loss 16.129170409229022
Epoch 13: loss 16.12917602029814
Epoch 14: loss 16.12916983749116
Epoch 15: loss 16.129163602307283
Epoch 16: loss 16.1291714285041
Epoch 17: loss 16.129169981138677
Epoch 18: loss 16.129180063949843
Epoch 19: loss 16.129167994706123
-----------Time: 0:02:30.039175, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1e-15, embedding_dim: 150, rmse: 4.017190933227539-------------


Epoch 0: loss 16.129172187191173
Epoch 1: loss 16.129171873189108
Epoch 2: loss 16.1291704437148
Epoch 3: loss 16.12917105823577
Epoch 4: loss 16.12917390629414
Epoch 5: loss 16.129179989273876
Epoch 6: loss 16.129169624872087
Epoch 7: loss 16.12917118502934
Epoch 8: loss 16.129170501536816
Epoch 9: loss 16.129178938105937
Epoch 10: loss 16.129171301710535
Epoch 11: loss 16.129176225397753
Epoch 12: loss 16.12917284319879
Epoch 13: loss 16.12917237388109
Epoch 14: loss 16.12917372893872
Epoch 15: loss 16.129175984515904
Epoch 16: loss 16.12917463749631
Epoch 17: loss 16.129179368270616
Epoch 18: loss 16.12917019116483
Epoch 19: loss 16.129175411740874
-----------Time: 0:02:59.909700, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1e-15, embedding_dim: 200, rmse: 4.0171895027160645-------------


Epoch 0: loss 16.129421554615213
Epoch 1: loss 16.129432274246422
Epoch 2: loss 16.129435465606807
Epoch 3: loss 16.12942957372494
Epoch 4: loss 16.129432459121297
Epoch 5: loss 16.129431362058753
Epoch 6: loss 16.129431903200217
Epoch 7: loss 16.129430009594035
Epoch 8: loss 16.129425010193685
Epoch 9: loss 16.129426304317803
Epoch 10: loss 16.12942880285117
Epoch 11: loss 16.12942842843417
Epoch 12: loss 16.12942853707733
Epoch 13: loss 16.129424164384652
Epoch 14: loss 16.129427548657947
Epoch 15: loss 16.129432472085874
Epoch 16: loss 16.129430056266514
Epoch 17: loss 16.129430741055494
Epoch 18: loss 16.129431573381368
Epoch 19: loss 16.12943057925757
-----------Time: 0:01:17.018840, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1.3219411484660287e-15, embedding_dim: 20, rmse: 4.017233371734619-------------


Epoch 0: loss 16.129178489272267
Epoch 1: loss 16.129175375440056
Epoch 2: loss 16.129185830334595
Epoch 3: loss 16.129184894292106
Epoch 4: loss 16.12917692937431
Epoch 5: loss 16.12918288452331
Epoch 6: loss 16.129185489366208
Epoch 7: loss 16.12918294130816
Epoch 8: loss 16.129185332754112
Epoch 9: loss 16.129177268786947
Epoch 10: loss 16.12918864546294
Epoch 11: loss 16.1291754783788
Epoch 12: loss 16.129178853576892
Epoch 13: loss 16.129178431709544
Epoch 14: loss 16.12917807077571
Epoch 15: loss 16.129181266544045
Epoch 16: loss 16.129180423327927
Epoch 17: loss 16.129180146923137
Epoch 18: loss 16.129178231017885
Epoch 19: loss 16.12918456395467
-----------Time: 0:01:32.775145, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1.3219411484660287e-15, embedding_dim: 50, rmse: 4.017183303833008-------------


Epoch 0: loss 16.129167578024603
Epoch 1: loss 16.129172619430186
Epoch 2: loss 16.129174767142082
Epoch 3: loss 16.129170334553056
Epoch 4: loss 16.129173916925094
Epoch 5: loss 16.129163435582818
Epoch 6: loss 16.12917093740591
Epoch 7: loss 16.129175767229587
Epoch 8: loss 16.12916736696128
Epoch 9: loss 16.12916830455952
Epoch 10: loss 16.129168050713094
Epoch 11: loss 16.12917447232759
Epoch 12: loss 16.129167252095126
Epoch 13: loss 16.12917263395051
Epoch 14: loss 16.129169862123856
Epoch 15: loss 16.129172406292533
Epoch 16: loss 16.12917315927519
Epoch 17: loss 16.129168880964635
Epoch 18: loss 16.129177896531786
Epoch 19: loss 16.12917088736264
-----------Time: 0:02:01.608649, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1.3219411484660287e-15, embedding_dim: 100, rmse: 4.017191410064697-------------


Epoch 0: loss 16.129178343550414
Epoch 1: loss 16.12917941053514
Epoch 2: loss 16.129176382787723
Epoch 3: loss 16.12917886809722
Epoch 4: loss 16.129181330329768
Epoch 5: loss 16.129176468613228
Epoch 6: loss 16.129178680110847
Epoch 7: loss 16.129177278380734
Epoch 8: loss 16.12917843974758
Epoch 9: loss 16.129172657546043
Epoch 10: loss 16.129181490312654
Epoch 11: loss 16.129178630067578
Epoch 12: loss 16.129180812524545
Epoch 13: loss 16.12918298020189
Epoch 14: loss 16.12917412824771
Epoch 15: loss 16.129183015724834
Epoch 16: loss 16.129180365246622
Epoch 17: loss 16.129187267069067
Epoch 18: loss 16.129184290142796
Epoch 19: loss 16.129180993250753
-----------Time: 0:02:29.759421, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1.3219411484660287e-15, embedding_dim: 150, rmse: 4.017189025878906-------------


Epoch 0: loss 16.129175059622952
Epoch 1: loss 16.129176459797314
Epoch 2: loss 16.129182038714276
Epoch 3: loss 16.129170665927656
Epoch 4: loss 16.12917241225624
Epoch 5: loss 16.12917401623376
Epoch 6: loss 16.129174670426337
Epoch 7: loss 16.129172537234766
Epoch 8: loss 16.129172641210676
Epoch 9: loss 16.129170499981065
Epoch 10: loss 16.129174359276476
Epoch 11: loss 16.12917235106343
Epoch 12: loss 16.129174720469607
Epoch 13: loss 16.129171671200993
Epoch 14: loss 16.129180881236802
Epoch 15: loss 16.129175073883985
Epoch 16: loss 16.12916700887965
Epoch 17: loss 16.12917591658152
Epoch 18: loss 16.129174159103403
Epoch 19: loss 16.12917984303344
-----------Time: 0:02:59.613333, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1.3219411484660287e-15, embedding_dim: 200, rmse: 4.017187118530273-------------


Epoch 0: loss 16.129292427423923
Epoch 1: loss 16.12929278161618
Epoch 2: loss 16.129294199163073
Epoch 3: loss 16.129290487923136
Epoch 4: loss 16.12929846762055
Epoch 5: loss 16.129290159141455
Epoch 6: loss 16.12929464721887
Epoch 7: loss 16.129290639608694
Epoch 8: loss 16.12929374644003
Epoch 9: loss 16.129298707983818
Epoch 10: loss 16.1292935755669
Epoch 11: loss 16.129296372026253
Epoch 12: loss 16.129299186636015
Epoch 13: loss 16.129302095887194
Epoch 14: loss 16.129297110488583
Epoch 15: loss 16.12929423001877
Epoch 16: loss 16.129298581968126
Epoch 17: loss 16.129292052488342
Epoch 18: loss 16.129293592939433
Epoch 19: loss 16.129304744550364
-----------Time: 0:01:16.183336, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1.747528400007683e-15, embedding_dim: 20, rmse: 4.017242431640625-------------


Epoch 0: loss 16.12923736738212
Epoch 1: loss 16.12922844023339
Epoch 2: loss 16.129236342661923
Epoch 3: loss 16.129231129864625
Epoch 4: loss 16.129224503409805
Epoch 5: loss 16.129230684142453
Epoch 6: loss 16.12922918180722
Epoch 7: loss 16.129231364264186
Epoch 8: loss 16.129228513612897
Epoch 9: loss 16.129226691830475
Epoch 10: loss 16.129233830386106
Epoch 11: loss 16.129232323383622
Epoch 12: loss 16.12923272450765
Epoch 13: loss 16.129227675841904
Epoch 14: loss 16.129224782926094
Epoch 15: loss 16.12922600600433
Epoch 16: loss 16.1292323516464
Epoch 17: loss 16.129233957438963
Epoch 18: loss 16.129227237898476
Epoch 19: loss 16.129232559598226
-----------Time: 0:01:32.726763, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1.747528400007683e-15, embedding_dim: 50, rmse: 4.017190933227539-------------


Epoch 0: loss 16.129174276821765
Epoch 1: loss 16.12917240758899
Epoch 2: loss 16.129180863345688
Epoch 3: loss 16.129186112962383
Epoch 4: loss 16.12917784830356
Epoch 5: loss 16.129183613651144
Epoch 6: loss 16.129182290486373
Epoch 7: loss 16.129187374156476
Epoch 8: loss 16.12917446688247
Epoch 9: loss 16.129180544417082
Epoch 10: loss 16.12918447475838
Epoch 11: loss 16.129185014862674
Epoch 12: loss 16.12918276265628
Epoch 13: loss 16.129176144758084
Epoch 14: loss 16.129177381060188
Epoch 15: loss 16.12918108503996
Epoch 16: loss 16.129177869565464
Epoch 17: loss 16.129177188925148
Epoch 18: loss 16.12917507621761
Epoch 19: loss 16.129182184176837
-----------Time: 0:02:01.405518, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1.747528400007683e-15, embedding_dim: 100, rmse: 4.017187118530273-------------


Epoch 0: loss 16.129177386505308
Epoch 1: loss 16.129178420819297
Epoch 2: loss 16.12918301702129
Epoch 3: loss 16.12917304518691
Epoch 4: loss 16.129178617621584
Epoch 5: loss 16.129178647958696
Epoch 6: loss 16.12917562228561
Epoch 7: loss 16.12917954173666
Epoch 8: loss 16.129178598174718
Epoch 9: loss 16.129173590477034
Epoch 10: loss 16.1291752053448
Epoch 11: loss 16.12917884527956
Epoch 12: loss 16.129172927987128
Epoch 13: loss 16.12917625340124
Epoch 14: loss 16.12917240447749
Epoch 15: loss 16.12917997682788
Epoch 16: loss 16.12918140630219
Epoch 17: loss 16.12918021382036
Epoch 18: loss 16.129179260146042
Epoch 19: loss 16.129173187019386
-----------Time: 0:02:29.839327, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1.747528400007683e-15, embedding_dim: 150, rmse: 4.01718807220459-------------


Epoch 0: loss 16.129171728504424
Epoch 1: loss 16.1291787275612
Epoch 2: loss 16.12917971416554
Epoch 3: loss 16.12917831554693
Epoch 4: loss 16.12917592306381
Epoch 5: loss 16.129172289352045
Epoch 6: loss 16.12917713343676
Epoch 7: loss 16.129168494101645
Epoch 8: loss 16.129174847522464
Epoch 9: loss 16.129178025658977
Epoch 10: loss 16.129175083477772
Epoch 11: loss 16.129176503099004
Epoch 12: loss 16.129183125145868
Epoch 13: loss 16.129164362809398
Epoch 14: loss 16.12917788227075
Epoch 15: loss 16.129182688498897
Epoch 16: loss 16.129170883473265
Epoch 17: loss 16.129176339486037
Epoch 18: loss 16.129172797044895
Epoch 19: loss 16.129175624878528
-----------Time: 0:02:59.754609, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 1.747528400007683e-15, embedding_dim: 200, rmse: 4.017190933227539-------------


Epoch 0: loss 16.129226286298493
Epoch 1: loss 16.129219309022208
Epoch 2: loss 16.12921928801959
Epoch 3: loss 16.129222268575944
Epoch 4: loss 16.129219422851197
Epoch 5: loss 16.129214165974336
Epoch 6: loss 16.129215717834256
Epoch 7: loss 16.129221447658903
Epoch 8: loss 16.129222661921226
Epoch 9: loss 16.129215795881013
Epoch 10: loss 16.129217004957503
Epoch 11: loss 16.129215325266852
Epoch 12: loss 16.129209711086236
Epoch 13: loss 16.12922039752813
Epoch 14: loss 16.129225596842264
Epoch 15: loss 16.129217743160545
Epoch 16: loss 16.129222171600905
Epoch 17: loss 16.129224091914118
Epoch 18: loss 16.129220318184917
Epoch 19: loss 16.129216891128515
-----------Time: 0:01:16.143403, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 2.310129700083158e-15, embedding_dim: 20, rmse: 4.0172200202941895-------------


Epoch 0: loss 16.12915656643111
Epoch 1: loss 16.12916297041378
Epoch 2: loss 16.129164029360467
Epoch 3: loss 16.129159554247625
Epoch 4: loss 16.12915878026235
Epoch 5: loss 16.129166576122056
Epoch 6: loss 16.129159568508662
Epoch 7: loss 16.129160503513987
Epoch 8: loss 16.1291610062803
Epoch 9: loss 16.129155442142952
Epoch 10: loss 16.12915689936146
Epoch 11: loss 16.12915995200086
Epoch 12: loss 16.129157483804608
Epoch 13: loss 16.129162413714827
Epoch 14: loss 16.12915473686994
Epoch 15: loss 16.129167894878876
Epoch 16: loss 16.12915728492799
Epoch 17: loss 16.1291603803505
Epoch 18: loss 16.12915677075285
Epoch 19: loss 16.129159528577762
-----------Time: 0:01:32.723585, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 2.310129700083158e-15, embedding_dim: 50, rmse: 4.017195224761963-------------


Epoch 0: loss 16.129169145701308
Epoch 1: loss 16.129177001716652
Epoch 2: loss 16.129175244757118
Epoch 3: loss 16.129183700254522
Epoch 4: loss 16.129177633091572
Epoch 5: loss 16.129181172680504
Epoch 6: loss 16.12917824372317
Epoch 7: loss 16.12917848667935
Epoch 8: loss 16.12917520871559
Epoch 9: loss 16.12918004528085
Epoch 10: loss 16.129168963678637
Epoch 11: loss 16.12917315953448
Epoch 12: loss 16.12917332029524
Epoch 13: loss 16.129175147004204
Epoch 14: loss 16.129171206550534
Epoch 15: loss 16.129178524535916
Epoch 16: loss 16.129175763080923
Epoch 17: loss 16.12917180629189
Epoch 18: loss 16.129180854789066
Epoch 19: loss 16.129178035771346
-----------Time: 0:02:01.660720, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 2.310129700083158e-15, embedding_dim: 100, rmse: 4.017192363739014-------------


Epoch 0: loss 16.12918041477131
Epoch 1: loss 16.12917043826968
Epoch 2: loss 16.12917032651502
Epoch 3: loss 16.129171618046225
Epoch 4: loss 16.129166581048597
Epoch 5: loss 16.1291685537387
Epoch 6: loss 16.129172139222238
Epoch 7: loss 16.129176237325165
Epoch 8: loss 16.12917043049093
Epoch 9: loss 16.12917160067369
Epoch 10: loss 16.129168608449216
Epoch 11: loss 16.129174930236466
Epoch 12: loss 16.129170394449407
Epoch 13: loss 16.129168017005195
Epoch 14: loss 16.12917133904852
Epoch 15: loss 16.129172135851448
Epoch 16: loss 16.129171562557833
Epoch 17: loss 16.12917190923063
Epoch 18: loss 16.129177911052114
Epoch 19: loss 16.12917042349006
-----------Time: 0:02:29.776084, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 2.310129700083158e-15, embedding_dim: 150, rmse: 4.0171895027160645-------------


Epoch 0: loss 16.12917310456467
Epoch 1: loss 16.129181370260664
Epoch 2: loss 16.1291755398309
Epoch 3: loss 16.129180240008804
Epoch 4: loss 16.129180196188532
Epoch 5: loss 16.129175458672645
Epoch 6: loss 16.129176908890276
Epoch 7: loss 16.12917979921317
Epoch 8: loss 16.12917257820283
Epoch 9: loss 16.12917343179061
Epoch 10: loss 16.129171689092107
Epoch 11: loss 16.12917228027684
Epoch 12: loss 16.12917686273638
Epoch 13: loss 16.129178186160445
Epoch 14: loss 16.129177454439695
Epoch 15: loss 16.129179498694267
Epoch 16: loss 16.12917573948539
Epoch 17: loss 16.12918381071272
Epoch 18: loss 16.129173601626572
Epoch 19: loss 16.12916954008375
-----------Time: 0:02:59.340042, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 2.310129700083158e-15, embedding_dim: 200, rmse: 4.017188549041748-------------


Epoch 0: loss 16.129296340651976
Epoch 1: loss 16.12930338975202
Epoch 2: loss 16.12929136614361
Epoch 3: loss 16.1292999357293
Epoch 4: loss 16.129288370807643
Epoch 5: loss 16.129292777467512
Epoch 6: loss 16.12929656545775
Epoch 7: loss 16.129292747389695
Epoch 8: loss 16.129301117061598
Epoch 9: loss 16.12929044799224
Epoch 10: loss 16.129294527426175
Epoch 11: loss 16.12929684704837
Epoch 12: loss 16.129297705044106
Epoch 13: loss 16.129291411260343
Epoch 14: loss 16.12930283694244
Epoch 15: loss 16.12928977175988
Epoch 16: loss 16.129297889400398
Epoch 17: loss 16.12929209916082
Epoch 18: loss 16.129300226135836
Epoch 19: loss 16.129291779713633
-----------Time: 0:01:16.040786, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 3.0538555088334123e-15, embedding_dim: 20, rmse: 4.017212867736816-------------


Epoch 0: loss 16.129170027551865
Epoch 1: loss 16.12917838244415
Epoch 2: loss 16.129170077595134
Epoch 3: loss 16.129168400238104
Epoch 4: loss 16.129168313634725
Epoch 5: loss 16.1291713395671
Epoch 6: loss 16.129179219177978
Epoch 7: loss 16.12916704829197
Epoch 8: loss 16.129170503611146
Epoch 9: loss 16.12916624137667
Epoch 10: loss 16.129176083305985
Epoch 11: loss 16.129172274572426
Epoch 12: loss 16.129167269986244
Epoch 13: loss 16.129173287365216
Epoch 14: loss 16.129178224276302
Epoch 15: loss 16.12916839453369
Epoch 16: loss 16.129181061963013
Epoch 17: loss 16.129171512773855
Epoch 18: loss 16.129166715880203
Epoch 19: loss 16.12917150862519
-----------Time: 0:01:32.722475, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 3.0538555088334123e-15, embedding_dim: 50, rmse: 4.017183780670166-------------


Epoch 0: loss 16.129160940420245
Epoch 1: loss 16.12916930568419
Epoch 2: loss 16.12916164465609
Epoch 3: loss 16.129165869811878
Epoch 4: loss 16.129160208180913
Epoch 5: loss 16.129166483295684
Epoch 6: loss 16.12916105347136
Epoch 7: loss 16.129167116744938
Epoch 8: loss 16.12916663964849
Epoch 9: loss 16.12916412218684
Epoch 10: loss 16.129166123917596
Epoch 11: loss 16.129156796682004
Epoch 12: loss 16.12916146237413
Epoch 13: loss 16.129163458141182
Epoch 14: loss 16.129164188046893
Epoch 15: loss 16.12916412685409
Epoch 16: loss 16.129168511733468
Epoch 17: loss 16.129166445439118
Epoch 18: loss 16.12916628467836
Epoch 19: loss 16.129162308183165
-----------Time: 0:02:01.698605, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 3.0538555088334123e-15, embedding_dim: 100, rmse: 4.01718807220459-------------


Epoch 0: loss 16.129175289355263
Epoch 1: loss 16.12918092790928
Epoch 2: loss 16.129184601551945
Epoch 3: loss 16.129181371297832
Epoch 4: loss 16.12917899878016
Epoch 5: loss 16.129186426705157
Epoch 6: loss 16.129181381410202
Epoch 7: loss 16.129177563342147
Epoch 8: loss 16.12917745184678
Epoch 9: loss 16.12917616057487
Epoch 10: loss 16.12917499920802
Epoch 11: loss 16.129179608893175
Epoch 12: loss 16.129177115804932
Epoch 13: loss 16.129180206560193
Epoch 14: loss 16.129179655824945
Epoch 15: loss 16.129168493064476
Epoch 16: loss 16.129175917877976
Epoch 17: loss 16.12917653317682
Epoch 18: loss 16.129176995752946
Epoch 19: loss 16.129181428601264
-----------Time: 0:02:29.822707, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 3.0538555088334123e-15, embedding_dim: 150, rmse: 4.017187118530273-------------


Epoch 0: loss 16.129183852717954
Epoch 1: loss 16.129174059276156
Epoch 2: loss 16.129176808285155
Epoch 3: loss 16.12917547448943
Epoch 4: loss 16.12917228572196
Epoch 5: loss 16.12918391935588
Epoch 6: loss 16.129172952101243
Epoch 7: loss 16.12917620776593
Epoch 8: loss 16.129177863083175
Epoch 9: loss 16.129168603004096
Epoch 10: loss 16.12917435772073
Epoch 11: loss 16.12917259998332
Epoch 12: loss 16.129174900936523
Epoch 13: loss 16.129178309842516
Epoch 14: loss 16.129167812942747
Epoch 15: loss 16.12917916965329
Epoch 16: loss 16.12917767924547
Epoch 17: loss 16.129175373365726
Epoch 18: loss 16.129174991169982
Epoch 19: loss 16.12917384432346
-----------Time: 0:02:59.367522, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 3.0538555088334123e-15, embedding_dim: 200, rmse: 4.017189025878906-------------


Epoch 0: loss 16.129266802936613
Epoch 1: loss 16.12926721909955
Epoch 2: loss 16.1292666714758
Epoch 3: loss 16.129267946153053
Epoch 4: loss 16.12926772264374
Epoch 5: loss 16.12926837942923
Epoch 6: loss 16.129260897830882
Epoch 7: loss 16.12926911918802
Epoch 8: loss 16.129269287208942
Epoch 9: loss 16.129261333181393
Epoch 10: loss 16.12927503544329
Epoch 11: loss 16.129267465945105
Epoch 12: loss 16.12927165350362
Epoch 13: loss 16.129265224369664
Epoch 14: loss 16.129263253494603
Epoch 15: loss 16.129269470268778
Epoch 16: loss 16.129270936303193
Epoch 17: loss 16.12926878418334
Epoch 18: loss 16.129266919099226
Epoch 19: loss 16.129275119972334
-----------Time: 0:01:16.309318, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 4.037017258596549e-15, embedding_dim: 20, rmse: 4.017226219177246-------------


Epoch 0: loss 16.12917988322363
Epoch 1: loss 16.129178186160445
Epoch 2: loss 16.12917660318554
Epoch 3: loss 16.129179864036058
Epoch 4: loss 16.12917996127039
Epoch 5: loss 16.129176612260746
Epoch 6: loss 16.129177110100517
Epoch 7: loss 16.12917264873013
Epoch 8: loss 16.12917234769264
Epoch 9: loss 16.129170062556224
Epoch 10: loss 16.129171651494833
Epoch 11: loss 16.12918604710233
Epoch 12: loss 16.12918264804942
Epoch 13: loss 16.12917724596929
Epoch 14: loss 16.129176724274693
Epoch 15: loss 16.129183638802424
Epoch 16: loss 16.12917223982736
Epoch 17: loss 16.12917215452044
Epoch 18: loss 16.129174291860675
Epoch 19: loss 16.129179910449245
-----------Time: 0:01:32.605532, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 4.037017258596549e-15, embedding_dim: 50, rmse: 4.017176151275635-------------


Epoch 0: loss 16.129160389944285
Epoch 1: loss 16.129163421581076
Epoch 2: loss 16.12916337205639
Epoch 3: loss 16.129162368338804
Epoch 4: loss 16.12916341224658
Epoch 5: loss 16.129169413030894
Epoch 6: loss 16.129171620120555
Epoch 7: loss 16.12916585658801
Epoch 8: loss 16.129160024343204
Epoch 9: loss 16.129165646561855
Epoch 10: loss 16.129167727376533
Epoch 11: loss 16.129162033852705
Epoch 12: loss 16.129163925384553
Epoch 13: loss 16.12916831285685
Epoch 14: loss 16.129162225209868
Epoch 15: loss 16.129160473176874
Epoch 16: loss 16.129161658657836
Epoch 17: loss 16.12916042105927
Epoch 18: loss 16.129168275000286
Epoch 19: loss 16.1291706646312
-----------Time: 0:02:01.265418, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 4.037017258596549e-15, embedding_dim: 100, rmse: 4.017188549041748-------------


Epoch 0: loss 16.129178815461035
Epoch 1: loss 16.12917158407903
Epoch 2: loss 16.129178044068677
Epoch 3: loss 16.12917728797452
Epoch 4: loss 16.129174417617076
Epoch 5: loss 16.129169160999506
Epoch 6: loss 16.12917993119257
Epoch 7: loss 16.129169160480924
Epoch 8: loss 16.12916625667487
Epoch 9: loss 16.129174114245963
Epoch 10: loss 16.129179235513345
Epoch 11: loss 16.129169383730947
Epoch 12: loss 16.129170301882322
Epoch 13: loss 16.12917235054485
Epoch 14: loss 16.129180647096536
Epoch 15: loss 16.1291750212478
Epoch 16: loss 16.12917318416718
Epoch 17: loss 16.129174923494887
Epoch 18: loss 16.12917676679851
Epoch 19: loss 16.1291713395671
-----------Time: 0:02:30.031478, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 4.037017258596549e-15, embedding_dim: 150, rmse: 4.0171895027160645-------------


Epoch 0: loss 16.129177990654618
Epoch 1: loss 16.129166561861023
Epoch 2: loss 16.129180294200737
Epoch 3: loss 16.129178233351507
Epoch 4: loss 16.129177019089184
Epoch 5: loss 16.12917991926516
Epoch 6: loss 16.129181800684634
Epoch 7: loss 16.12917896014572
Epoch 8: loss 16.1291753311012
Epoch 9: loss 16.129172365324468
Epoch 10: loss 16.12917741710171
Epoch 11: loss 16.129180092471913
Epoch 12: loss 16.12917771476841
Epoch 13: loss 16.129175872501957
Epoch 14: loss 16.129170524873054
Epoch 15: loss 16.129175542683107
Epoch 16: loss 16.129177414768087
Epoch 17: loss 16.129173110269086
Epoch 18: loss 16.129173555731967
Epoch 19: loss 16.129174635421975
-----------Time: 0:02:59.372147, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 4.037017258596549e-15, embedding_dim: 200, rmse: 4.017187118530273-------------


Epoch 0: loss 16.129400185880097
Epoch 1: loss 16.12939830342345
Epoch 2: loss 16.129396930993284
Epoch 3: loss 16.129406616829087
Epoch 4: loss 16.1293989462072
Epoch 5: loss 16.129398694694398
Epoch 6: loss 16.129410217610825
Epoch 7: loss 16.129394160463086
Epoch 8: loss 16.129397180691047
Epoch 9: loss 16.129400004894595
Epoch 10: loss 16.129407829794953
Epoch 11: loss 16.129402954595253
Epoch 12: loss 16.12940169651266
Epoch 13: loss 16.12940597767542
Epoch 14: loss 16.129396630215087
Epoch 15: loss 16.129400621230605
Epoch 16: loss 16.12940082788597
Epoch 17: loss 16.129403574042765
Epoch 18: loss 16.1294018456053
Epoch 19: loss 16.129400285966632
-----------Time: 0:01:16.441219, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 5.336699231206302e-15, embedding_dim: 20, rmse: 4.017195224761963-------------


Epoch 0: loss 16.12918634191682
Epoch 1: loss 16.12918276706424
Epoch 2: loss 16.12918531045504
Epoch 3: loss 16.12918021589469
Epoch 4: loss 16.129187174761277
Epoch 5: loss 16.12918661443224
Epoch 6: loss 16.129183259199596
Epoch 7: loss 16.129187847622845
Epoch 8: loss 16.12918062583463
Epoch 9: loss 16.129186876575996
Epoch 10: loss 16.129188250561914
Epoch 11: loss 16.12918713871975
Epoch 12: loss 16.129184635259847
Epoch 13: loss 16.129183444852348
Epoch 14: loss 16.129190119276103
Epoch 15: loss 16.12918378971011
Epoch 16: loss 16.129185046496243
Epoch 17: loss 16.129185778216993
Epoch 18: loss 16.129188326275045
Epoch 19: loss 16.129185061794445
-----------Time: 0:01:32.477754, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 5.336699231206302e-15, embedding_dim: 50, rmse: 4.017178535461426-------------


Epoch 0: loss 16.12917158356045
Epoch 1: loss 16.12917114198694
Epoch 2: loss 16.12917516515461
Epoch 3: loss 16.129177408804384
Epoch 4: loss 16.129169783817808
Epoch 5: loss 16.1291739044791
Epoch 6: loss 16.129171887709436
Epoch 7: loss 16.129172016318044
Epoch 8: loss 16.129166398248056
Epoch 9: loss 16.129171986499514
Epoch 10: loss 16.129174782180993
Epoch 11: loss 16.129172305946703
Epoch 12: loss 16.129177289789563
Epoch 13: loss 16.129177329201877
Epoch 14: loss 16.129169068951008
Epoch 15: loss 16.12917556524147
Epoch 16: loss 16.129170647517956
Epoch 17: loss 16.129175941214218
Epoch 18: loss 16.129170653481662
Epoch 19: loss 16.12917101960133
-----------Time: 0:02:01.281320, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 5.336699231206302e-15, embedding_dim: 100, rmse: 4.017190456390381-------------


Epoch 0: loss 16.12917394933654
Epoch 1: loss 16.129173557287718
Epoch 2: loss 16.129177254007327
Epoch 3: loss 16.129173599292947
Epoch 4: loss 16.12917946628282
Epoch 5: loss 16.12917196394115
Epoch 6: loss 16.129164482861384
Epoch 7: loss 16.129168861258478
Epoch 8: loss 16.12916699332216
Epoch 9: loss 16.129170684337357
Epoch 10: loss 16.129176135164297
Epoch 11: loss 16.12917850794126
Epoch 12: loss 16.129174036717792
Epoch 13: loss 16.1291793166716
Epoch 14: loss 16.12917863395695
Epoch 15: loss 16.129169807672632
Epoch 16: loss 16.129172905688055
Epoch 17: loss 16.129169132736727
Epoch 18: loss 16.129172293241417
Epoch 19: loss 16.129176515285707
-----------Time: 0:02:29.837566, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 5.336699231206302e-15, embedding_dim: 150, rmse: 4.017188549041748-------------


Epoch 0: loss 16.129171747692
Epoch 1: loss 16.129168590298807
Epoch 2: loss 16.129170352962756
Epoch 3: loss 16.129182411834815
Epoch 4: loss 16.129171376905084
Epoch 5: loss 16.12917029695578
Epoch 6: loss 16.1291717998096
Epoch 7: loss 16.129171975868562
Epoch 8: loss 16.129170894622803
Epoch 9: loss 16.12917399626831
Epoch 10: loss 16.12916652141154
Epoch 11: loss 16.129168245700342
Epoch 12: loss 16.129173292810336
Epoch 13: loss 16.129168873704472
Epoch 14: loss 16.129171450543883
Epoch 15: loss 16.129172040172865
Epoch 16: loss 16.129174338533154
Epoch 17: loss 16.129171936974828
Epoch 18: loss 16.129179706646088
Epoch 19: loss 16.12917375538646
-----------Time: 0:02:59.238162, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 5.336699231206302e-15, embedding_dim: 200, rmse: 4.017187595367432-------------


Epoch 0: loss 16.12929299319808
Epoch 1: loss 16.12928934833678
Epoch 2: loss 16.129298691389156
Epoch 3: loss 16.129295204954992
Epoch 4: loss 16.129291434855872
Epoch 5: loss 16.129296777298944
Epoch 6: loss 16.12929704592499
Epoch 7: loss 16.129298264595267
Epoch 8: loss 16.129298272114724
Epoch 9: loss 16.129293956984768
Epoch 10: loss 16.12929292578228
Epoch 11: loss 16.129293870640684
Epoch 12: loss 16.129299341951654
Epoch 13: loss 16.129295958974815
Epoch 14: loss 16.129303256735458
Epoch 15: loss 16.129300383007223
Epoch 16: loss 16.12929392042466
Epoch 17: loss 16.129299138148497
Epoch 18: loss 16.129293511003304
Epoch 19: loss 16.1292954839527
-----------Time: 0:01:16.332804, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 7.054802310718631e-15, embedding_dim: 20, rmse: 4.017221450805664-------------


Epoch 0: loss 16.12918768115767
Epoch 1: loss 16.129186928175013
Epoch 2: loss 16.12918899213574
Epoch 3: loss 16.129185754362172
Epoch 4: loss 16.129193278225042
Epoch 5: loss 16.129184490575163
Epoch 6: loss 16.129186968105913
Epoch 7: loss 16.12918912904168
Epoch 8: loss 16.129190157910546
Epoch 9: loss 16.129186490750172
Epoch 10: loss 16.129187438460782
Epoch 11: loss 16.129186379254804
Epoch 12: loss 16.129191860418853
Epoch 13: loss 16.129184556175925
Epoch 14: loss 16.12918671866744
Epoch 15: loss 16.12919021884406
Epoch 16: loss 16.12918338340025
Epoch 17: loss 16.129189372775734
Epoch 18: loss 16.129188881677543
Epoch 19: loss 16.12919146448066
-----------Time: 0:01:32.567117, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 7.054802310718631e-15, embedding_dim: 50, rmse: 4.017193794250488-------------


Epoch 0: loss 16.129188056093252
Epoch 1: loss 16.12918535375673
Epoch 2: loss 16.129186859981335
Epoch 3: loss 16.129188994210075
Epoch 4: loss 16.129187176576316
Epoch 5: loss 16.129187984788075
Epoch 6: loss 16.129187682454127
Epoch 7: loss 16.129185729729475
Epoch 8: loss 16.129186257647067
Epoch 9: loss 16.129189479863143
Epoch 10: loss 16.129189578653225
Epoch 11: loss 16.12918959006205
Epoch 12: loss 16.129181095411624
Epoch 13: loss 16.129185185735807
Epoch 14: loss 16.12918125746884
Epoch 15: loss 16.129186255572737
Epoch 16: loss 16.129181878990682
Epoch 17: loss 16.129191308646437
Epoch 18: loss 16.129189853502265
Epoch 19: loss 16.129187908815652
-----------Time: 0:02:01.694727, Loss: regression, n_iter: 20, l2: 1e-15, batch_size: 256, learning_rate: 7.054802310718631e-15, embedding_dim: 100, rmse: 4.017187118530273-------------


Epoch 0: loss 16.12917689981507
Epoch 1: loss 16.129174478291297
Epoch 2: loss 16.12917728097365
Epoch 3: loss 16.129179885557257
Epoch 4: loss 16.129175385293134
Epoch 5: loss 16.129169870161892
Epoch 6: loss 16.12917839592731
Epoch 7: loss 16.12916939591765
Epoch 8: loss 16.129174367055224
Epoch 9: loss 16.12917982254941
Epoch 10: loss 16.129177022459974
Epoch 11: loss 16.129176366452356
Epoch 12: loss 16.129177752884267
Epoch 13: loss 16.12917248122779
Epoch 14: loss 16.129178122634016
Epoch 15: loss 16.129177054093542
Epoch 16: loss 16.129181054962142
Epoch 17: loss 16.129180201892947