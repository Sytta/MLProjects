{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyfm import pylibfm\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"./datas/data_train.csv\"\n",
    "pred_dataset = \"./datas/sampleSubmission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    \"\"\"Load dataset as a (User, Movie, Rating) pandas dataframe\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    parsed_df = pd.DataFrame()\n",
    "    # Get all pairs of (r44_c1) -> (44, 1) (user, movie)\n",
    "    user_movie_indices = df.Id.apply(lambda x: x.split('_'))\n",
    "    parsed_df['User'] =  [int(i[0][1:]) for i in user_movie_indices]\n",
    "    parsed_df['Movie'] = [int(i[1][1:]) for i in user_movie_indices]\n",
    "    parsed_df['Rating'] = df['Prediction']\n",
    "    \n",
    "    num_items = parsed_df.Movie.nunique()\n",
    "    num_users = parsed_df.User.nunique()\n",
    "    print(\"USERS: {} ITEMS: {}\".format(num_users, num_items))\n",
    "    return parsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USERS: 10000 ITEMS: 1000\n"
     ]
    }
   ],
   "source": [
    "train_df = load_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies per user: min[3], max[522], users per movie: min[8], max[4590].\n",
      "The shape of test_dataset: (117695, 3), train_dataset: (1059257, 3)\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(parsed_df, p_test=0.1, min_num_ratings=0):\n",
    "    movies_per_user = parsed_df.User.value_counts()\n",
    "    users_per_movie = parsed_df.Movie.value_counts()\n",
    "\n",
    "    valid_users = movies_per_user[movies_per_user > min_num_ratings].index.values\n",
    "    valid_movies = users_per_movie[users_per_movie > min_num_ratings].index.values\n",
    "    valid_parsed_df = parsed_df[parsed_df.User.isin(valid_users) & parsed_df.Movie.isin(valid_movies)].reset_index(drop=True)\n",
    "    \n",
    "    print(\"movies per user: min[{a}], max[{b}], users per movie: min[{c}], max[{d}].\".\n",
    "          format(a=movies_per_user.min(), b=movies_per_user.max(), c=users_per_movie.min(), d=users_per_movie.max()))\n",
    "\n",
    "    size = valid_parsed_df.shape[0]\n",
    "    indexes = list(range(size))\n",
    "    np.random.shuffle(indexes)\n",
    "\n",
    "    test_ind = indexes[:int(size*p_test)]\n",
    "    train_ind = indexes[int(size*p_test):]\n",
    "\n",
    "    test = valid_parsed_df.loc[test_ind].reset_index(drop=True)\n",
    "    train = valid_parsed_df.loc[train_ind].reset_index(drop=True)\n",
    "    print(\"The shape of test_dataset: {test}, train_dataset: {train}\".format(test=test.shape, train=train.shape))\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "train, test = split_dataset(train_df)\n",
    "# print(train.iloc[0,2])\n",
    "# type(train.iloc[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(pred, real):\n",
    "    pred_sorted = pred.sort_values(['Movie', 'User']).reset_index(drop=True)\n",
    "    real_sorted = real.sort_values(['Movie', 'User']).reset_index(drop=True)\n",
    "\n",
    "    mse = np.square(pred_sorted.Rating - real_sorted.Rating).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toPyFMData(df):\n",
    "    \"\"\"Transform pandas dataframe into the dataformat PyFM needs\"\"\"\n",
    "    data = []\n",
    "    users = set(df.User.unique())\n",
    "    movies = set(df.Movie.unique())\n",
    "    ratings = df.Rating.astype(float).tolist()\n",
    "    for row in df.iterrows():\n",
    "        data.append({\"user_id\": str(row[1].User), \"movie_id\": str(row[1].Movie)})\n",
    "    return (data, np.array(ratings), users, movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, y_train, train_users, train_items) = toPyFMData(train)\n",
    "(test_data, y_test, test_users, test_items) = toPyFMData(test)\n",
    "v = DictVectorizer()\n",
    "X_train = v.fit_transform(train_data)\n",
    "X_test = v.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.54478\n",
      "-- Epoch 2\n",
      "Training MSE: 0.51169\n",
      "-- Epoch 3\n",
      "Training MSE: 0.50290\n",
      "-- Epoch 4\n",
      "Training MSE: 0.49799\n",
      "-- Epoch 5\n",
      "Training MSE: 0.49478\n",
      "-- Epoch 6\n",
      "Training MSE: 0.49248\n",
      "-- Epoch 7\n",
      "Training MSE: 0.49073\n",
      "-- Epoch 8\n",
      "Training MSE: 0.48928\n",
      "-- Epoch 9\n",
      "Training MSE: 0.48798\n",
      "-- Epoch 10\n",
      "Training MSE: 0.48684\n",
      "-- Epoch 11\n",
      "Training MSE: 0.48573\n",
      "-- Epoch 12\n",
      "Training MSE: 0.48469\n",
      "-- Epoch 13\n",
      "Training MSE: 0.48357\n",
      "-- Epoch 14\n",
      "Training MSE: 0.48248\n",
      "-- Epoch 15\n",
      "Training MSE: 0.48131\n",
      "-- Epoch 16\n",
      "Training MSE: 0.48005\n",
      "-- Epoch 17\n",
      "Training MSE: 0.47884\n",
      "-- Epoch 18\n",
      "Training MSE: 0.47743\n",
      "-- Epoch 19\n",
      "Training MSE: 0.47609\n",
      "-- Epoch 20\n",
      "Training MSE: 0.47462\n",
      "-- Epoch 21\n",
      "Training MSE: 0.47317\n",
      "-- Epoch 22\n",
      "Training MSE: 0.47165\n",
      "-- Epoch 23\n",
      "Training MSE: 0.47017\n",
      "-- Epoch 24\n",
      "Training MSE: 0.46874\n",
      "-- Epoch 25\n",
      "Training MSE: 0.46731\n",
      "-- Epoch 26\n",
      "Training MSE: 0.46590\n",
      "-- Epoch 27\n",
      "Training MSE: 0.46464\n",
      "-- Epoch 28\n",
      "Training MSE: 0.46338\n",
      "-- Epoch 29\n",
      "Training MSE: 0.46226\n",
      "-- Epoch 30\n",
      "Training MSE: 0.46116\n",
      "-- Epoch 31\n",
      "Training MSE: 0.46012\n",
      "-- Epoch 32\n",
      "Training MSE: 0.45919\n",
      "-- Epoch 33\n",
      "Training MSE: 0.45825\n",
      "-- Epoch 34\n",
      "Training MSE: 0.45738\n",
      "-- Epoch 35\n",
      "Training MSE: 0.45652\n",
      "-- Epoch 36\n",
      "Training MSE: 0.45572\n",
      "-- Epoch 37\n",
      "Training MSE: 0.45488\n",
      "-- Epoch 38\n",
      "Training MSE: 0.45414\n",
      "-- Epoch 39\n",
      "Training MSE: 0.45337\n",
      "-- Epoch 40\n",
      "Training MSE: 0.45262\n",
      "-- Epoch 41\n",
      "Training MSE: 0.45193\n",
      "-- Epoch 42\n",
      "Training MSE: 0.45121\n",
      "-- Epoch 43\n",
      "Training MSE: 0.45054\n",
      "-- Epoch 44\n",
      "Training MSE: 0.44984\n",
      "-- Epoch 45\n",
      "Training MSE: 0.44922\n",
      "-- Epoch 46\n",
      "Training MSE: 0.44857\n",
      "-- Epoch 47\n",
      "Training MSE: 0.44796\n",
      "-- Epoch 48\n",
      "Training MSE: 0.44733\n",
      "-- Epoch 49\n",
      "Training MSE: 0.44680\n",
      "-- Epoch 50\n",
      "Training MSE: 0.44619\n",
      "-- Epoch 51\n",
      "Training MSE: 0.44565\n",
      "-- Epoch 52\n",
      "Training MSE: 0.44515\n",
      "-- Epoch 53\n",
      "Training MSE: 0.44464\n",
      "-- Epoch 54\n",
      "Training MSE: 0.44412\n",
      "-- Epoch 55\n",
      "Training MSE: 0.44361\n",
      "-- Epoch 56\n",
      "Training MSE: 0.44321\n",
      "-- Epoch 57\n",
      "Training MSE: 0.44273\n",
      "-- Epoch 58\n",
      "Training MSE: 0.44234\n",
      "-- Epoch 59\n",
      "Training MSE: 0.44196\n",
      "-- Epoch 60\n",
      "Training MSE: 0.44164\n",
      "-- Epoch 61\n",
      "Training MSE: 0.44127\n",
      "-- Epoch 62\n",
      "Training MSE: 0.44104\n",
      "-- Epoch 63\n",
      "Training MSE: 0.44067\n",
      "-- Epoch 64\n",
      "Training MSE: 0.44041\n",
      "-- Epoch 65\n",
      "Training MSE: 0.44017\n",
      "-- Epoch 66\n",
      "Training MSE: 0.43994\n",
      "-- Epoch 67\n",
      "Training MSE: 0.43966\n",
      "-- Epoch 68\n",
      "Training MSE: 0.43955\n",
      "-- Epoch 69\n",
      "Training MSE: 0.43933\n",
      "-- Epoch 70\n",
      "Training MSE: 0.43914\n",
      "-- Epoch 71\n",
      "Training MSE: 0.43897\n",
      "-- Epoch 72\n",
      "Training MSE: 0.43885\n",
      "-- Epoch 73\n",
      "Training MSE: 0.43867\n",
      "-- Epoch 74\n",
      "Training MSE: 0.43854\n",
      "-- Epoch 75\n",
      "Training MSE: 0.43837\n",
      "-- Epoch 76\n",
      "Training MSE: 0.43826\n",
      "-- Epoch 77\n",
      "Training MSE: 0.43811\n",
      "-- Epoch 78\n",
      "Training MSE: 0.43798\n",
      "-- Epoch 79\n",
      "Training MSE: 0.43794\n",
      "-- Epoch 80\n",
      "Training MSE: 0.43772\n",
      "-- Epoch 81\n",
      "Training MSE: 0.43763\n",
      "-- Epoch 82\n",
      "Training MSE: 0.43749\n",
      "-- Epoch 83\n",
      "Training MSE: 0.43737\n",
      "-- Epoch 84\n",
      "Training MSE: 0.43726\n",
      "-- Epoch 85\n",
      "Training MSE: 0.43707\n",
      "-- Epoch 86\n",
      "Training MSE: 0.43704\n",
      "-- Epoch 87\n",
      "Training MSE: 0.43686\n",
      "-- Epoch 88\n",
      "Training MSE: 0.43677\n",
      "-- Epoch 89\n",
      "Training MSE: 0.43667\n",
      "-- Epoch 90\n",
      "Training MSE: 0.43655\n",
      "-- Epoch 91\n",
      "Training MSE: 0.43647\n",
      "-- Epoch 92\n",
      "Training MSE: 0.43636\n",
      "-- Epoch 93\n",
      "Training MSE: 0.43624\n",
      "-- Epoch 94\n",
      "Training MSE: 0.43614\n",
      "-- Epoch 95\n",
      "Training MSE: 0.43602\n",
      "-- Epoch 96\n",
      "Training MSE: 0.43588\n",
      "-- Epoch 97\n",
      "Training MSE: 0.43584\n",
      "-- Epoch 98\n",
      "Training MSE: 0.43570\n",
      "-- Epoch 99\n",
      "Training MSE: 0.43562\n",
      "-- Epoch 100\n",
      "Training MSE: 0.43551\n",
      "-- Epoch 101\n",
      "Training MSE: 0.43539\n",
      "-- Epoch 102\n",
      "Training MSE: 0.43536\n",
      "-- Epoch 103\n",
      "Training MSE: 0.43525\n",
      "-- Epoch 104\n",
      "Training MSE: 0.43514\n",
      "-- Epoch 105\n",
      "Training MSE: 0.43504\n",
      "-- Epoch 106\n",
      "Training MSE: 0.43498\n",
      "-- Epoch 107\n",
      "Training MSE: 0.43488\n",
      "-- Epoch 108\n",
      "Training MSE: 0.43476\n",
      "-- Epoch 109\n",
      "Training MSE: 0.43469\n",
      "-- Epoch 110\n",
      "Training MSE: 0.43462\n",
      "-- Epoch 111\n",
      "Training MSE: 0.43455\n",
      "-- Epoch 112\n",
      "Training MSE: 0.43445\n",
      "-- Epoch 113\n",
      "Training MSE: 0.43438\n",
      "-- Epoch 114\n",
      "Training MSE: 0.43427\n",
      "-- Epoch 115\n",
      "Training MSE: 0.43421\n",
      "-- Epoch 116\n",
      "Training MSE: 0.43416\n",
      "-- Epoch 117\n",
      "Training MSE: 0.43410\n",
      "-- Epoch 118\n",
      "Training MSE: 0.43404\n",
      "-- Epoch 119\n",
      "Training MSE: 0.43398\n",
      "-- Epoch 120\n",
      "Training MSE: 0.43388\n",
      "-- Epoch 121\n",
      "Training MSE: 0.43381\n",
      "-- Epoch 122\n",
      "Training MSE: 0.43372\n",
      "-- Epoch 123\n",
      "Training MSE: 0.43368\n",
      "-- Epoch 124\n",
      "Training MSE: 0.43365\n",
      "-- Epoch 125\n",
      "Training MSE: 0.43360\n",
      "-- Epoch 126\n",
      "Training MSE: 0.43351\n",
      "-- Epoch 127\n",
      "Training MSE: 0.43349\n",
      "-- Epoch 128\n",
      "Training MSE: 0.43345\n",
      "-- Epoch 129\n",
      "Training MSE: 0.43343\n",
      "-- Epoch 130\n",
      "Training MSE: 0.43329\n",
      "-- Epoch 131\n",
      "Training MSE: 0.43326\n",
      "-- Epoch 132\n",
      "Training MSE: 0.43321\n",
      "-- Epoch 133\n",
      "Training MSE: 0.43318\n",
      "-- Epoch 134\n",
      "Training MSE: 0.43310\n",
      "-- Epoch 135\n",
      "Training MSE: 0.43303\n",
      "-- Epoch 136\n",
      "Training MSE: 0.43301\n",
      "-- Epoch 137\n",
      "Training MSE: 0.43298\n",
      "-- Epoch 138\n",
      "Training MSE: 0.43291\n",
      "-- Epoch 139\n",
      "Training MSE: 0.43286\n",
      "-- Epoch 140\n",
      "Training MSE: 0.43280\n",
      "-- Epoch 141\n",
      "Training MSE: 0.43276\n",
      "-- Epoch 142\n",
      "Training MSE: 0.43269\n",
      "-- Epoch 143\n",
      "Training MSE: 0.43267\n",
      "-- Epoch 144\n",
      "Training MSE: 0.43262\n",
      "-- Epoch 145\n",
      "Training MSE: 0.43261\n",
      "-- Epoch 146\n",
      "Training MSE: 0.43254\n",
      "-- Epoch 147\n",
      "Training MSE: 0.43251\n",
      "-- Epoch 148\n",
      "Training MSE: 0.43246\n",
      "-- Epoch 149\n",
      "Training MSE: 0.43239\n",
      "-- Epoch 150\n",
      "Training MSE: 0.43236\n",
      "-- Epoch 151\n",
      "Training MSE: 0.43230\n",
      "-- Epoch 152\n",
      "Training MSE: 0.43229\n",
      "-- Epoch 153\n",
      "Training MSE: 0.43225\n",
      "-- Epoch 154\n",
      "Training MSE: 0.43219\n",
      "-- Epoch 155\n",
      "Training MSE: 0.43217\n",
      "-- Epoch 156\n",
      "Training MSE: 0.43211\n",
      "-- Epoch 157\n",
      "Training MSE: 0.43210\n",
      "-- Epoch 158\n",
      "Training MSE: 0.43203\n",
      "-- Epoch 159\n",
      "Training MSE: 0.43195\n",
      "-- Epoch 160\n",
      "Training MSE: 0.43193\n",
      "-- Epoch 161\n",
      "Training MSE: 0.43186\n",
      "-- Epoch 162\n",
      "Training MSE: 0.43187\n",
      "-- Epoch 163\n",
      "Training MSE: 0.43184\n",
      "-- Epoch 164\n",
      "Training MSE: 0.43180\n",
      "-- Epoch 165\n",
      "Training MSE: 0.43175\n",
      "-- Epoch 166\n",
      "Training MSE: 0.43168\n",
      "-- Epoch 167\n",
      "Training MSE: 0.43169\n",
      "-- Epoch 168\n",
      "Training MSE: 0.43162\n",
      "-- Epoch 169\n",
      "Training MSE: 0.43161\n",
      "-- Epoch 170\n",
      "Training MSE: 0.43156\n",
      "-- Epoch 171\n",
      "Training MSE: 0.43155\n",
      "-- Epoch 172\n",
      "Training MSE: 0.43150\n",
      "-- Epoch 173\n",
      "Training MSE: 0.43149\n",
      "-- Epoch 174\n",
      "Training MSE: 0.43148\n",
      "-- Epoch 175\n",
      "Training MSE: 0.43143\n",
      "-- Epoch 176\n",
      "Training MSE: 0.43140\n",
      "-- Epoch 177\n",
      "Training MSE: 0.43136\n",
      "-- Epoch 178\n",
      "Training MSE: 0.43136\n",
      "-- Epoch 179\n",
      "Training MSE: 0.43130\n",
      "-- Epoch 180\n",
      "Training MSE: 0.43128\n",
      "-- Epoch 181\n",
      "Training MSE: 0.43131\n",
      "-- Epoch 182\n",
      "Training MSE: 0.43123\n",
      "-- Epoch 183\n",
      "Training MSE: 0.43119\n",
      "-- Epoch 184\n",
      "Training MSE: 0.43122\n",
      "-- Epoch 185\n",
      "Training MSE: 0.43116\n",
      "-- Epoch 186\n",
      "Training MSE: 0.43113\n",
      "-- Epoch 187\n",
      "Training MSE: 0.43116\n",
      "-- Epoch 188\n",
      "Training MSE: 0.43107\n",
      "-- Epoch 189\n",
      "Training MSE: 0.43110\n",
      "-- Epoch 190\n",
      "Training MSE: 0.43110\n",
      "-- Epoch 191\n",
      "Training MSE: 0.43108\n",
      "-- Epoch 192\n",
      "Training MSE: 0.43110\n",
      "-- Epoch 193\n",
      "Training MSE: 0.43105\n",
      "-- Epoch 194\n",
      "Training MSE: 0.43100\n",
      "-- Epoch 195\n",
      "Training MSE: 0.43102\n",
      "-- Epoch 196\n",
      "Training MSE: 0.43099\n",
      "-- Epoch 197\n",
      "Training MSE: 0.43098\n",
      "-- Epoch 198\n",
      "Training MSE: 0.43097\n",
      "-- Epoch 199\n",
      "Training MSE: 0.43097\n",
      "-- Epoch 200\n",
      "Training MSE: 0.43091\n"
     ]
    }
   ],
   "source": [
    "fm = pylibfm.FM(num_factors=20, num_iter=200, verbose=True, task=\"regression\", initial_learning_rate=0.001, learning_rate_schedule=\"optimal\")\n",
    "fm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM MSE: 0.9756\n"
     ]
    }
   ],
   "source": [
    "preds = fm.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"FM MSE: %.4f\" % mean_squared_error(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9877478639054355\n"
     ]
    }
   ],
   "source": [
    "preds = fm.predict(X_test)\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] > 5:\n",
    "        preds[i] = 5\n",
    "    elif preds[i] < 1:\n",
    "        preds[i] = 1\n",
    "predictions = test.copy()\n",
    "predictions['Rating'] = preds\n",
    "\n",
    "rmse = compute_rmse(predictions, test)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "from pyfm import pylibfm\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyFM_cv_algo(algo, k_fold=5, verbose=True):\n",
    "    \n",
    "    kf = KFold(n_splits=k_fold)\n",
    "    rmse_ = 0\n",
    "    \n",
    "    for trainset_ind, testset_ind in kf.split(train_df):\n",
    "        \n",
    "        trainset = train_df.iloc[trainset_ind]\n",
    "        testset = train_df.iloc[testset_ind]\n",
    "        \n",
    "        (train_data, y_train, train_users, train_items) = toPyFMData(trainset)\n",
    "        (test_data, y_test, test_users, test_items) = toPyFMData(testset)\n",
    "        v = DictVectorizer()\n",
    "        X_train = v.fit_transform(train_data)\n",
    "        X_test = v.transform(test_data)\n",
    "    \n",
    "        algo.fit(X_train,y_train)\n",
    "        preds = algo.predict(X_test)\n",
    "        for i in range(len(preds)):\n",
    "            if preds[i] > 5:\n",
    "                preds[i] = 5\n",
    "            elif preds[i] < 1:\n",
    "                preds[i] = 1\n",
    "        predictions = testset.copy()\n",
    "        predictions['Rating'] = preds\n",
    "\n",
    "        rmse_ += compute_rmse(predictions, testset)\n",
    "        \n",
    "    rmse_mean = rmse_/k_fold\n",
    "    return rmse_mean\n",
    "        \n",
    "def pyFM_cv(verbose=True, t = Timer()): \n",
    "    #pyFM parameters\n",
    "    factors = np.linspace(20, 200, 9, dtype=np.int64)\n",
    "    learning_rates = np.logspace(-2, -5, 4)\n",
    "    params = dict()\n",
    "    rmses = dict()\n",
    "    \n",
    "    for k in factors:\n",
    "        params['k'] = k\n",
    "        for rate in learning_rates:\n",
    "            params['rate'] = rate\n",
    "            algo = pylibfm.FM(num_factors=k, num_iter=200, verbose=True, task=\"regression\", initial_learning_rate=rate, learning_rate_schedule=\"optimal\")\n",
    "            rmse = pyFM_cv_algo(algo)\n",
    "            print(\"------Time:{}, rmse: {}, factors: {}, learning_rates: {}------\\n\\n\".format(t.now(), rmse, k, rate))\n",
    "            rmses[rmse] = params\n",
    "    \n",
    "    # Find the model with least RMSE\n",
    "    lowest_rmse = min(rmses.keys())\n",
    "    best_params = rmses[lowest_rmse]\n",
    "    \n",
    "    print(\"Best pyFM rmse: {}. Params: factors: {}, learning_rates: {}\".format(lowest_rmse, best_params['k'], best_params['rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.50892\n",
      "-- Epoch 2\n",
      "Training MSE: 0.49226\n",
      "-- Epoch 3\n",
      "Training MSE: 0.48633\n",
      "-- Epoch 4\n",
      "Training MSE: 0.47756\n",
      "-- Epoch 5\n",
      "Training MSE: 0.46932\n",
      "-- Epoch 6\n",
      "Training MSE: 0.46355\n",
      "-- Epoch 7\n",
      "Training MSE: 0.45967\n",
      "-- Epoch 8\n",
      "Training MSE: 0.45701\n",
      "-- Epoch 9\n",
      "Training MSE: 0.45415\n",
      "-- Epoch 10\n",
      "Training MSE: 0.45137\n",
      "-- Epoch 11\n",
      "Training MSE: 0.44841\n",
      "-- Epoch 12\n",
      "Training MSE: 0.44768\n",
      "-- Epoch 13\n",
      "Training MSE: 0.44580\n",
      "-- Epoch 14\n",
      "Training MSE: 0.44467\n",
      "-- Epoch 15\n",
      "Training MSE: 0.44405\n",
      "-- Epoch 16\n",
      "Training MSE: 0.44272\n",
      "-- Epoch 17\n",
      "Training MSE: 0.44264\n",
      "-- Epoch 18\n",
      "Training MSE: 0.44253\n",
      "-- Epoch 19\n",
      "Training MSE: 0.44248\n",
      "-- Epoch 20\n",
      "Training MSE: 0.44198\n",
      "-- Epoch 21\n",
      "Training MSE: 0.44090\n",
      "-- Epoch 22\n",
      "Training MSE: 0.44163\n",
      "-- Epoch 23\n",
      "Training MSE: 0.44088\n",
      "-- Epoch 24\n",
      "Training MSE: 0.44080\n",
      "-- Epoch 25\n",
      "Training MSE: 0.44010\n",
      "-- Epoch 26\n"
     ]
    }
   ],
   "source": [
    "train_dataset = \"./datas/data_train.csv\"\n",
    "train_df = load_dataset(train_dataset)\n",
    "\n",
    "t = Timer()\n",
    "t.start()\n",
    "pyFM_cv()\n",
    "t.stop(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.53516\n",
      "-- Epoch 2\n",
      "Training MSE: 0.50306\n",
      "-- Epoch 3\n",
      "Training MSE: 0.49337\n",
      "predictions['Rating']: 3.749767021609181\n",
      "rmse: 1.1636358262542048\n",
      "FM MSE: 1.3540\n",
      "[3.74976702 3.93636196 3.52732125 ... 3.29428063 3.47435704 3.26056977]\n",
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.55050\n",
      "-- Epoch 2\n",
      "Training MSE: 0.51776\n",
      "-- Epoch 3\n",
      "Training MSE: 0.50824\n",
      "predictions['Rating']: 4.118604735906454\n",
      "rmse: 1.1109504440837479\n",
      "FM MSE: 1.2342\n",
      "[4.11860474 4.26118996 3.74162908 ... 3.4761124  3.4774119  3.50195492]\n",
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.54992\n",
      "-- Epoch 2\n",
      "Training MSE: 0.51694\n",
      "-- Epoch 3\n",
      "Training MSE: 0.50749\n",
      "predictions['Rating']: 3.4944698156105924\n",
      "rmse: 1.107797901943358\n",
      "FM MSE: 1.2272\n",
      "[3.49446982 3.55253983 3.49709276 ... 4.20767293 4.29337989 4.13934643]\n",
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.56147\n",
      "-- Epoch 2\n",
      "Training MSE: 0.52882\n",
      "-- Epoch 3\n",
      "Training MSE: 0.51921\n",
      "predictions['Rating']: 4.092977131326308\n",
      "rmse: 1.1534210173907302\n",
      "FM MSE: 1.3304\n",
      "[4.09297713 4.1161709  4.31529854 ... 3.59793851 3.52510371 3.70374613]\n",
      "Creating validation dataset of 0.01 of training for adaptive regularization\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "from pyfm import pylibfm\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def compute_rmse_test(pred, truth):\n",
    "    \"\"\" compute RMSE for pandas dataframes \"\"\"\n",
    "    truth_sorted = truth.sort_values(['User', 'Movie']).reset_index(drop=True)\n",
    "    pred_sorted = pred.sort_values(['User', 'Movie']).reset_index(drop=True)\n",
    "\n",
    "    truth_sorted['square_error'] = np.square(truth_sorted['Rating'] - pred_sorted['Rating'])\n",
    "\n",
    "    mse = truth_sorted['square_error'].mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def pyFM_cv_algo(algo, k_fold=5, verbose=True):\n",
    "    \n",
    "    kf = KFold(n_splits=k_fold)\n",
    "    rmse_ = 0\n",
    "    \n",
    "    for trainset_ind, testset_ind in kf.split(train_df):\n",
    "        \n",
    "        trainset = train_df.iloc[trainset_ind]\n",
    "        testset = train_df.iloc[testset_ind]\n",
    "        \n",
    "        (train_data, y_train, train_users, train_items) = toPyFMData(trainset)\n",
    "        (test_data, y_test, test_users, test_items) = toPyFMData(testset)\n",
    "        v = DictVectorizer()\n",
    "        X_train = v.fit_transform(train_data)\n",
    "        X_test = v.transform(test_data)\n",
    "    \n",
    "        algo.fit(X_train,y_train)\n",
    "        preds = algo.predict(X_test)\n",
    "        for i in range(len(preds)):\n",
    "            if preds[i] > 5:\n",
    "                preds[i] = 5\n",
    "            elif preds[i] < 1:\n",
    "                preds[i] = 1\n",
    "        predictions = testset.copy()\n",
    "        predictions['Rating'] = preds\n",
    "        print(\"predictions['Rating']: {}\".format(predictions['Rating'].iloc[0]))\n",
    "        rmse = compute_rmse_test(predictions, testset)\n",
    "        print(\"rmse: {}\".format(rmse))\n",
    "        print(\"FM MSE: %.4f\" % mean_squared_error(y_test,preds))\n",
    "        print(preds)\n",
    "        rmse_ += rmse\n",
    "        \n",
    "    rmse_mean = rmse_/k_fold\n",
    "    return rmse_mean\n",
    "    \n",
    "train_dataset = \"./datas/data_train.csv\"\n",
    "train_df = load_dataset(train_dataset)\n",
    "\n",
    "t = Timer()\n",
    "t.start()\n",
    "algo = pylibfm.FM(num_factors=40, num_iter=3, verbose=True, task=\"regression\", initial_learning_rate=0.001, learning_rate_schedule=\"optimal\")\n",
    "rmse = pyFM_cv_algo(algo)\n",
    "print(\"------Time:{}, rmse: {}, factors: {}, learning_rates: {}------\\n\\n\".format(t.now(), rmse,20, 0.001))\n",
    "t.stop(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
