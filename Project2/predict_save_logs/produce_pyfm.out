Loading baseline models...
1 model families loaded:
 pyfm: pyfm, ; 

[load_dataset] Valid: (1176952, 3)
[load_dataset] Valid: (1176952, 3)
Splitting data for training...
[split_dataset] Valid: (1176952, 3)
Results of split:    User  Movie  Rating
0  4292    161       3
1  7913    757       4
2  7963    418       2
3  8809    168       2
4  4814    416       4; 
    User  Movie  Rating
0  1207    877       3
1  2337    179       3
2  4221    971       4
3  2306    148       5
4  3092    188       4
Predicting using algo: <function pyfm_algo at 0x7f556bdf7158>, model: pyfm...
Time: 0:00:00.000014, predicting with model: pyfm
Creating validation dataset of 0.01 of training for adaptive regularization
-- Epoch 1
Training MSE: 0.56224
-- Epoch 2
Training MSE: 0.52259
-- Epoch 3
Training MSE: 0.51160
-- Epoch 4
Training MSE: 0.50491
-- Epoch 5
Training MSE: 0.50023
-- Epoch 6
Training MSE: 0.49668
-- Epoch 7
Training MSE: 0.49385
-- Epoch 8
Training MSE: 0.49144
-- Epoch 9
Training MSE: 0.48939
-- Epoch 10
Training MSE: 0.48760
-- Epoch 11
Training MSE: 0.48598
-- Epoch 12
Training MSE: 0.48438
-- Epoch 13
Training MSE: 0.48289
-- Epoch 14
Training MSE: 0.48146
-- Epoch 15
Training MSE: 0.48001
-- Epoch 16
Training MSE: 0.47856
-- Epoch 17
Training MSE: 0.47711
-- Epoch 18
Training MSE: 0.47561
-- Epoch 19
Training MSE: 0.47410
-- Epoch 20
Training MSE: 0.47253
-- Epoch 21
Training MSE: 0.47084
-- Epoch 22
Training MSE: 0.46914
-- Epoch 23
Training MSE: 0.46742
-- Epoch 24
Training MSE: 0.46558
-- Epoch 25
Training MSE: 0.46375
-- Epoch 26
Training MSE: 0.46185
-- Epoch 27
Training MSE: 0.45995
-- Epoch 28
Training MSE: 0.45799
-- Epoch 29
Training MSE: 0.45611
-- Epoch 30
Training MSE: 0.45420
-- Epoch 31
Training MSE: 0.45242
-- Epoch 32
Training MSE: 0.45067
-- Epoch 33
Training MSE: 0.44900
-- Epoch 34
Training MSE: 0.44747
-- Epoch 35
Training MSE: 0.44604
-- Epoch 36
Training MSE: 0.44472
-- Epoch 37
Training MSE: 0.44356
-- Epoch 38
Training MSE: 0.44258
-- Epoch 39
Training MSE: 0.44166
-- Epoch 40
Training MSE: 0.44095
-- Epoch 41
Training MSE: 0.44033
-- Epoch 42
Training MSE: 0.43982
-- Epoch 43
Training MSE: 0.43934
-- Epoch 44
Training MSE: 0.43903
-- Epoch 45
Training MSE: 0.43877
-- Epoch 46
Training MSE: 0.43852
-- Epoch 47
Training MSE: 0.43842
-- Epoch 48
Training MSE: 0.43830
-- Epoch 49
Training MSE: 0.43821
-- Epoch 50
Training MSE: 0.43812
-- Epoch 51
Training MSE: 0.43809
-- Epoch 52
Training MSE: 0.43806
-- Epoch 53
Training MSE: 0.43803
-- Epoch 54
Training MSE: 0.43809
-- Epoch 55
Training MSE: 0.43809
-- Epoch 56
Training MSE: 0.43812
-- Epoch 57
Training MSE: 0.43811
-- Epoch 58
Training MSE: 0.43816
-- Epoch 59
Training MSE: 0.43819
-- Epoch 60
Training MSE: 0.43824
-- Epoch 61
Training MSE: 0.43823
-- Epoch 62
Training MSE: 0.43827
-- Epoch 63
Training MSE: 0.43831
-- Epoch 64
Training MSE: 0.43839
-- Epoch 65
Training MSE: 0.43845
-- Epoch 66
Training MSE: 0.43848
-- Epoch 67
Training MSE: 0.43849
-- Epoch 68
Training MSE: 0.43858
-- Epoch 69
Training MSE: 0.43865
-- Epoch 70
Training MSE: 0.43870
-- Epoch 71
Training MSE: 0.43876
-- Epoch 72
Training MSE: 0.43878
-- Epoch 73
Training MSE: 0.43885
-- Epoch 74
Training MSE: 0.43890
-- Epoch 75
Training MSE: 0.43888
-- Epoch 76
Training MSE: 0.43899
-- Epoch 77
Training MSE: 0.43900
-- Epoch 78
Training MSE: 0.43911
-- Epoch 79
Training MSE: 0.43911
-- Epoch 80
Training MSE: 0.43919
-- Epoch 81
Training MSE: 0.43915
-- Epoch 82
Training MSE: 0.43922
-- Epoch 83
Training MSE: 0.43927
-- Epoch 84
Training MSE: 0.43931
-- Epoch 85
Training MSE: 0.43934
-- Epoch 86
Training MSE: 0.43937
-- Epoch 87
Training MSE: 0.43938
-- Epoch 88
Training MSE: 0.43941
-- Epoch 89
Training MSE: 0.43940
-- Epoch 90
Training MSE: 0.43942
-- Epoch 91
Training MSE: 0.43947
-- Epoch 92
Training MSE: 0.43947
-- Epoch 93
Training MSE: 0.43946
-- Epoch 94
Training MSE: 0.43951
-- Epoch 95
Training MSE: 0.43946
-- Epoch 96
Training MSE: 0.43946
-- Epoch 97
Training MSE: 0.43947
-- Epoch 98
Training MSE: 0.43948
-- Epoch 99
Training MSE: 0.43948
-- Epoch 100
Training MSE: 0.43941
-- Epoch 101
Training MSE: 0.43940
-- Epoch 102
Training MSE: 0.43935
-- Epoch 103
Training MSE: 0.43935
-- Epoch 104
Training MSE: 0.43924
-- Epoch 105
Training MSE: 0.43922
-- Epoch 106
Training MSE: 0.43918
-- Epoch 107
Training MSE: 0.43914
-- Epoch 108
Training MSE: 0.43909
-- Epoch 109
Training MSE: 0.43899
-- Epoch 110
Training MSE: 0.43898
-- Epoch 111
Training MSE: 0.43893
-- Epoch 112
Training MSE: 0.43878
-- Epoch 113
Training MSE: 0.43875
-- Epoch 114
Training MSE: 0.43870
-- Epoch 115
Training MSE: 0.43859
-- Epoch 116
Training MSE: 0.43851
-- Epoch 117
Training MSE: 0.43842
-- Epoch 118
Training MSE: 0.43833
-- Epoch 119
Training MSE: 0.43824
-- Epoch 120
Training MSE: 0.43820
-- Epoch 121
Training MSE: 0.43806
-- Epoch 122
Training MSE: 0.43797
-- Epoch 123
Training MSE: 0.43787
-- Epoch 124
Training MSE: 0.43775
-- Epoch 125
Training MSE: 0.43769
-- Epoch 126
Training MSE: 0.43761
-- Epoch 127
Training MSE: 0.43749
-- Epoch 128
Training MSE: 0.43737
-- Epoch 129
Training MSE: 0.43726
-- Epoch 130
Training MSE: 0.43718
-- Epoch 131
Training MSE: 0.43704
-- Epoch 132
Training MSE: 0.43693
-- Epoch 133
Training MSE: 0.43682
-- Epoch 134
Training MSE: 0.43675
-- Epoch 135
Training MSE: 0.43666
-- Epoch 136
Training MSE: 0.43652
-- Epoch 137
Training MSE: 0.43645
-- Epoch 138
Training MSE: 0.43633
-- Epoch 139
Training MSE: 0.43615
-- Epoch 140
Training MSE: 0.43614
-- Epoch 141
Training MSE: 0.43599
-- Epoch 142
Training MSE: 0.43595
-- Epoch 143
Training MSE: 0.43579
-- Epoch 144
Training MSE: 0.43572
-- Epoch 145
Training MSE: 0.43565
-- Epoch 146
Training MSE: 0.43553
-- Epoch 147
Training MSE: 0.43544
-- Epoch 148
Training MSE: 0.43531
-- Epoch 149
Training MSE: 0.43521
-- Epoch 150
Training MSE: 0.43514
-- Epoch 151
Training MSE: 0.43508
-- Epoch 152
Training MSE: 0.43495
-- Epoch 153
Training MSE: 0.43488
-- Epoch 154
Training MSE: 0.43479
-- Epoch 155
Training MSE: 0.43468
-- Epoch 156
Training MSE: 0.43460
-- Epoch 157
Training MSE: 0.43452
-- Epoch 158
Training MSE: 0.43439
-- Epoch 159
Training MSE: 0.43441
-- Epoch 160
Training MSE: 0.43426
-- Epoch 161
Training MSE: 0.43420
-- Epoch 162
Training MSE: 0.43415
-- Epoch 163
Training MSE: 0.43407
-- Epoch 164
Training MSE: 0.43400
-- Epoch 165
Training MSE: 0.43394
-- Epoch 166
Training MSE: 0.43390
-- Epoch 167
Training MSE: 0.43379
-- Epoch 168
Training MSE: 0.43372
-- Epoch 169
Training MSE: 0.43367
-- Epoch 170
Training MSE: 0.43360
-- Epoch 171
Training MSE: 0.43356
-- Epoch 172
Training MSE: 0.43353
-- Epoch 173
Training MSE: 0.43341
-- Epoch 174
Training MSE: 0.43336
-- Epoch 175
Training MSE: 0.43327
-- Epoch 176
Training MSE: 0.43323
-- Epoch 177
Training MSE: 0.43316
-- Epoch 178
Training MSE: 0.43315
-- Epoch 179
Training MSE: 0.43307
-- Epoch 180
Training MSE: 0.43303
-- Epoch 181
Training MSE: 0.43293
-- Epoch 182
Training MSE: 0.43292
-- Epoch 183
Training MSE: 0.43288
-- Epoch 184
Training MSE: 0.43281
-- Epoch 185
Training MSE: 0.43277
-- Epoch 186
Training MSE: 0.43275
-- Epoch 187
Training MSE: 0.43274
-- Epoch 188
Training MSE: 0.43268
-- Epoch 189
Training MSE: 0.43263
-- Epoch 190
Training MSE: 0.43262
-- Epoch 191
Training MSE: 0.43255
-- Epoch 192
Training MSE: 0.43251
-- Epoch 193
Training MSE: 0.43248
-- Epoch 194
Training MSE: 0.43246
-- Epoch 195
Training MSE: 0.43242
-- Epoch 196
Training MSE: 0.43238
-- Epoch 197
Training MSE: 0.43232
-- Epoch 198
Training MSE: 0.43232
-- Epoch 199
Training MSE: 0.43228
-- Epoch 200
Training MSE: 0.43225
Time: 1:11:39.488139, Saving results of pyfm...

Saving ground_truth to ./predict_save/ground_truth(1:11:42.865634).csv
