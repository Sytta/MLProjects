Loading pyfm models...
1 model families loaded:
 pyfm: pyfm, ; 

[load_dataset] Valid: (1176952, 3)
[load_dataset] Valid: (1176952, 3)
Splitting data for training...
[split_dataset] Valid: (1176952, 3)
Results of split:    User  Movie  Rating
0  4292    161       3
1  7913    757       4
2  7963    418       2
3  8809    168       2
4  4814    416       4; 
    User  Movie  Rating
0  1207    877       3
1  2337    179       3
2  4221    971       4
3  2306    148       5
4  3092    188       4
Predicting using algo: <function pyfm_algo at 0x7f2fb9c17730>, model: pyfm...
Time: 0:00:00.000033, predicting with model: pyfm
Creating validation dataset of 0.01 of training for adaptive regularization
-- Epoch 1
Training MSE: 0.56217
-- Epoch 2
Training MSE: 0.52261
-- Epoch 3
Training MSE: 0.51154
-- Epoch 4
Training MSE: 0.50486
-- Epoch 5
Training MSE: 0.50018
-- Epoch 6
Training MSE: 0.49662
-- Epoch 7
Training MSE: 0.49377
-- Epoch 8
Training MSE: 0.49138
-- Epoch 9
Training MSE: 0.48938
-- Epoch 10
Training MSE: 0.48756
-- Epoch 11
Training MSE: 0.48590
-- Epoch 12
Training MSE: 0.48440
-- Epoch 13
Training MSE: 0.48283
-- Epoch 14
Training MSE: 0.48137
-- Epoch 15
Training MSE: 0.47991
-- Epoch 16
Training MSE: 0.47848
-- Epoch 17
Training MSE: 0.47702
-- Epoch 18
Training MSE: 0.47549
-- Epoch 19
Training MSE: 0.47392
-- Epoch 20
Training MSE: 0.47230
-- Epoch 21
Training MSE: 0.47059
-- Epoch 22
Training MSE: 0.46883
-- Epoch 23
Training MSE: 0.46702
-- Epoch 24
Training MSE: 0.46515
-- Epoch 25
Training MSE: 0.46322
-- Epoch 26
Training MSE: 0.46119
-- Epoch 27
Training MSE: 0.45914
-- Epoch 28
Training MSE: 0.45708
-- Epoch 29
Training MSE: 0.45499
-- Epoch 30
Training MSE: 0.45283
-- Epoch 31
Training MSE: 0.45078
-- Epoch 32
Training MSE: 0.44870
-- Epoch 33
Training MSE: 0.44671
-- Epoch 34
Training MSE: 0.44483
-- Epoch 35
Training MSE: 0.44290
-- Epoch 36
Training MSE: 0.44125
-- Epoch 37
Training MSE: 0.43967
-- Epoch 38
Training MSE: 0.43819
-- Epoch 39
Training MSE: 0.43690
-- Epoch 40
Training MSE: 0.43573
-- Epoch 41
Training MSE: 0.43478
-- Epoch 42
Training MSE: 0.43396
-- Epoch 43
Training MSE: 0.43325
-- Epoch 44
Training MSE: 0.43260
-- Epoch 45
Training MSE: 0.43213
-- Epoch 46
Training MSE: 0.43174
-- Epoch 47
Training MSE: 0.43139
-- Epoch 48
Training MSE: 0.43113
-- Epoch 49
Training MSE: 0.43087
-- Epoch 50
Training MSE: 0.43061
-- Epoch 51
Training MSE: 0.43049
-- Epoch 52
Training MSE: 0.43034
-- Epoch 53
Training MSE: 0.43023
-- Epoch 54
Training MSE: 0.43014
-- Epoch 55
Training MSE: 0.43001
-- Epoch 56
Training MSE: 0.42991
-- Epoch 57
Training MSE: 0.42981
-- Epoch 58
Training MSE: 0.42975
-- Epoch 59
Training MSE: 0.42964
-- Epoch 60
Training MSE: 0.42962
-- Epoch 61
Training MSE: 0.42953
-- Epoch 62
Training MSE: 0.42951
-- Epoch 63
Training MSE: 0.42943
-- Epoch 64
Training MSE: 0.42934
-- Epoch 65
Training MSE: 0.42937
-- Epoch 66
Training MSE: 0.42926
-- Epoch 67
Training MSE: 0.42924
-- Epoch 68
Training MSE: 0.42917
-- Epoch 69
Training MSE: 0.42918
-- Epoch 70
Training MSE: 0.42911
-- Epoch 71
Training MSE: 0.42909
-- Epoch 72
Training MSE: 0.42907
-- Epoch 73
Training MSE: 0.42907
-- Epoch 74
Training MSE: 0.42908
-- Epoch 75
Training MSE: 0.42902
-- Epoch 76
Training MSE: 0.42904
-- Epoch 77
Training MSE: 0.42902
-- Epoch 78
Training MSE: 0.42898
-- Epoch 79
Training MSE: 0.42897
-- Epoch 80
Training MSE: 0.42900
-- Epoch 81
Training MSE: 0.42894
-- Epoch 82
Training MSE: 0.42901
-- Epoch 83
Training MSE: 0.42897
-- Epoch 84
Training MSE: 0.42895
-- Epoch 85
Training MSE: 0.42894
-- Epoch 86
Training MSE: 0.42894
-- Epoch 87
Training MSE: 0.42891
-- Epoch 88
Training MSE: 0.42894
-- Epoch 89
Training MSE: 0.42891
-- Epoch 90
Training MSE: 0.42891
-- Epoch 91
Training MSE: 0.42886
-- Epoch 92
Training MSE: 0.42889
-- Epoch 93
Training MSE: 0.42888
-- Epoch 94
Training MSE: 0.42890
-- Epoch 95
Training MSE: 0.42885
-- Epoch 96
Training MSE: 0.42883
-- Epoch 97
Training MSE: 0.42883
-- Epoch 98
Training MSE: 0.42881
-- Epoch 99
Training MSE: 0.42882
-- Epoch 100
Training MSE: 0.42879
-- Epoch 101
Training MSE: 0.42877
-- Epoch 102
Training MSE: 0.42872
-- Epoch 103
Training MSE: 0.42872
-- Epoch 104
Training MSE: 0.42872
-- Epoch 105
Training MSE: 0.42871
-- Epoch 106
Training MSE: 0.42870
-- Epoch 107
Training MSE: 0.42866
-- Epoch 108
Training MSE: 0.42861
-- Epoch 109
Training MSE: 0.42860
-- Epoch 110
Training MSE: 0.42859
-- Epoch 111
Training MSE: 0.42860
-- Epoch 112
Training MSE: 0.42853
-- Epoch 113
Training MSE: 0.42851
-- Epoch 114
Training MSE: 0.42851
-- Epoch 115
Training MSE: 0.42845
-- Epoch 116
Training MSE: 0.42843
-- Epoch 117
Training MSE: 0.42840
-- Epoch 118
Training MSE: 0.42840
-- Epoch 119
Training MSE: 0.42839
-- Epoch 120
Training MSE: 0.42836
-- Epoch 121
Training MSE: 0.42828
-- Epoch 122
Training MSE: 0.42827
-- Epoch 123
Training MSE: 0.42824
-- Epoch 124
Training MSE: 0.42817
-- Epoch 125
Training MSE: 0.42816
-- Epoch 126
Training MSE: 0.42810
-- Epoch 127
Training MSE: 0.42806
-- Epoch 128
Training MSE: 0.42799
-- Epoch 129
Training MSE: 0.42796
-- Epoch 130
Training MSE: 0.42793
-- Epoch 131
Training MSE: 0.42789
-- Epoch 132
Training MSE: 0.42785
-- Epoch 133
Training MSE: 0.42784
-- Epoch 134
Training MSE: 0.42778
-- Epoch 135
Training MSE: 0.42772
-- Epoch 136
Training MSE: 0.42767
-- Epoch 137
Training MSE: 0.42763
-- Epoch 138
Training MSE: 0.42765
-- Epoch 139
Training MSE: 0.42758
-- Epoch 140
Training MSE: 0.42751
-- Epoch 141
Training MSE: 0.42748
-- Epoch 142
Training MSE: 0.42745
-- Epoch 143
Training MSE: 0.42736
-- Epoch 144
Training MSE: 0.42734
-- Epoch 145
Training MSE: 0.42728
-- Epoch 146
Training MSE: 0.42725
-- Epoch 147
Training MSE: 0.42721
-- Epoch 148
Training MSE: 0.42712
-- Epoch 149
Training MSE: 0.42708
-- Epoch 150
Training MSE: 0.42706
-- Epoch 151
Training MSE: 0.42703
-- Epoch 152
Training MSE: 0.42695
-- Epoch 153
Training MSE: 0.42695
-- Epoch 154
Training MSE: 0.42688
-- Epoch 155
Training MSE: 0.42681
-- Epoch 156
Training MSE: 0.42681
-- Epoch 157
Training MSE: 0.42673
-- Epoch 158
Training MSE: 0.42669
-- Epoch 159
Training MSE: 0.42665
-- Epoch 160
Training MSE: 0.42661
-- Epoch 161
Training MSE: 0.42655
-- Epoch 162
Training MSE: 0.42651
-- Epoch 163
Training MSE: 0.42638
-- Epoch 164
Training MSE: 0.42645
-- Epoch 165
Training MSE: 0.42641
-- Epoch 166
Training MSE: 0.42632
-- Epoch 167
Training MSE: 0.42625
-- Epoch 168
Training MSE: 0.42623
-- Epoch 169
Training MSE: 0.42616
-- Epoch 170
Training MSE: 0.42619
-- Epoch 171
Training MSE: 0.42606
-- Epoch 172
Training MSE: 0.42607
-- Epoch 173
Training MSE: 0.42605
-- Epoch 174
Training MSE: 0.42598
-- Epoch 175
Training MSE: 0.42597
-- Epoch 176
Training MSE: 0.42593
-- Epoch 177
Training MSE: 0.42584
-- Epoch 178
Training MSE: 0.42581
-- Epoch 179
Training MSE: 0.42580
-- Epoch 180
Training MSE: 0.42573
-- Epoch 181
Training MSE: 0.42573
-- Epoch 182
Training MSE: 0.42570
-- Epoch 183
Training MSE: 0.42560
-- Epoch 184
Training MSE: 0.42567
-- Epoch 185
Training MSE: 0.42558
-- Epoch 186
Training MSE: 0.42552
-- Epoch 187
Training MSE: 0.42554
-- Epoch 188
Training MSE: 0.42549
-- Epoch 189
Training MSE: 0.42545
-- Epoch 190
Training MSE: 0.42546
-- Epoch 191
Training MSE: 0.42543
-- Epoch 192
Training MSE: 0.42537
-- Epoch 193
Training MSE: 0.42537
-- Epoch 194
Training MSE: 0.42533
-- Epoch 195
Training MSE: 0.42531
-- Epoch 196
Training MSE: 0.42532
-- Epoch 197
Training MSE: 0.42524
-- Epoch 198
Training MSE: 0.42527
-- Epoch 199
Training MSE: 0.42525
-- Epoch 200
Training MSE: 0.42520
Time: 1:11:07.713201, Saving results of pyfm...

Saving ground_truth to ./user_std_predict_save/ground_truth_1:11:10.291567.csv
[load_dataset] Valid: (1176952, 3)
[load_dataset] Valid: (1176952, 3)
Predicting using algo: <function pyfm_algo at 0x7f2fb9c17730>, model: pyfm...
Time: 0:00:00.000030, predicting with model: pyfm
Creating validation dataset of 0.01 of training for adaptive regularization
-- Epoch 1
Training MSE: 0.54274
-- Epoch 2
Training MSE: 0.51076
-- Epoch 3
Training MSE: 0.50240
-- Epoch 4
Training MSE: 0.49778
-- Epoch 5
Training MSE: 0.49486
-- Epoch 6
Training MSE: 0.49277