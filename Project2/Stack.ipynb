{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "4 model families loaded:\n",
      " baseline; surprise; spotlight; pyfm; \n",
      "Loading predictions from ./predict_save/....\n",
      "[load_predictions] files: ['global_mean_predictions.csv', 'global_median_predictions.csv', 'movie_mean_predictions.csv', 'movie_mean_user_habit_predictions.csv', 'movie_mean_user_habit_std_predictions.csv', 'movie_mean_user_std_predictions.csv', 'movie_median_predictions.csv', 'movie_median_user_habit_predictions.csv', 'movie_median_user_habit_std_predictions.csv', 'movie_median_user_std_predictions.csv', 'pyfm_predictions.csv', 'spotlight_predictions.csv', 'surprise_knn_predictions.csv', 'surprise_svd_predictions.csv', 'user_mean_predictions.csv', 'user_median_predictions.csv']\n",
      "Reading 1/16 : global_mean_predictions.csv...\n",
      "Reading 2/16 : global_median_predictions.csv...\n",
      "Reading 3/16 : movie_mean_predictions.csv...\n",
      "Reading 4/16 : movie_mean_user_habit_predictions.csv...\n",
      "Reading 5/16 : movie_mean_user_habit_std_predictions.csv...\n",
      "Reading 6/16 : movie_mean_user_std_predictions.csv...\n",
      "Reading 7/16 : movie_median_predictions.csv...\n",
      "Reading 8/16 : movie_median_user_habit_predictions.csv...\n",
      "Reading 9/16 : movie_median_user_habit_std_predictions.csv...\n",
      "Reading 10/16 : movie_median_user_std_predictions.csv...\n",
      "Reading 11/16 : pyfm_predictions.csv...\n",
      "Reading 12/16 : spotlight_predictions.csv...\n",
      "Reading 13/16 : surprise_knn_predictions.csv...\n",
      "Reading 14/16 : surprise_svd_predictions.csv...\n",
      "Reading 15/16 : user_mean_predictions.csv...\n",
      "Reading 16/16 : user_median_predictions.csv...\n",
      "Time: 0:00:19.882074, Finished loading.\n",
      "Optimizing...\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.9934234688806681\n",
      "            Iterations: 27\n",
      "            Function evaluations: 490\n",
      "            Gradient evaluations: 27\n",
      "Time: 0:04:28.671651. Optimization done.\n",
      "Loading models...\n",
      "4 model families loaded:\n",
      " baseline; surprise; spotlight; pyfm; \n",
      "Best weights: \n",
      " {'baseline': {'global_mean': 0.039218357737556234, 'global_median': 0.03834579880156073, 'user_mean': -0.0725975690066108, 'user_median': -0.00789918390882379, 'movie_mean': -0.007740758638513599, 'movie_median': 0.05957828523443381, 'movie_mean_user_std': 0.14060176214789746, 'movie_median_user_std': 0.16847202307620532, 'movie_mean_user_habit_std': -0.13447269055892114, 'movie_median_user_habit_std': -0.1456809113227612, 'movie_mean_user_habit': -0.11955677173311868, 'movie_median_user_habit': -0.05223704160233942}, 'surprise': {'surprise_svd': 0.013492358136093105, 'surprise_knn': 0.07331438341412916}, 'spotlight': {'spotlight': 0.5124571545404157}, 'pyfm': {'pyfm': 0.5034777822960248}}\n",
      "Best weights rmse: 0.9934234688806681\n",
      "Predicting....\n",
      "[load_dataset] Valid: (1176952, 3)\n",
      "[load_dataset] Valid: (1176952, 3)\n",
      "Loading models...\n",
      "4 model families loaded:\n",
      " baseline; surprise; spotlight; pyfm; \n",
      "Predicting using algo: <function baseline_algo at 0x7f904ff1c0d0>, model: baseline...\n",
      "Time: 0:00:00.000027, predicting with model: global_mean\n",
      "Time: 0:00:00.014177, Saving results of global_mean...\n",
      "\n",
      "Time: 0:00:04.813148, predicting with model: global_median\n",
      "Time: 0:00:04.839608, Saving results of global_median...\n",
      "\n",
      "Time: 0:00:08.626902, predicting with model: user_mean\n",
      "Time: 0:00:14.503855, Saving results of user_mean...\n",
      "\n",
      "Time: 0:00:19.500873, predicting with model: user_median\n",
      "Time: 0:00:25.515672, Saving results of user_median...\n",
      "\n",
      "Time: 0:00:29.622349, predicting with model: movie_mean\n",
      "Time: 0:00:30.414331, Saving results of movie_mean...\n",
      "\n",
      "Time: 0:00:35.236776, predicting with model: movie_median\n",
      "Time: 0:00:36.067120, Saving results of movie_median...\n",
      "\n",
      "Time: 0:00:40.046485, predicting with model: movie_mean_user_std\n",
      "Time: 0:02:35.547874, Saving results of movie_mean_user_std...\n",
      "\n",
      "Time: 0:02:40.476161, predicting with model: movie_median_user_std\n",
      "Time: 0:04:31.717898, Saving results of movie_median_user_std...\n",
      "\n",
      "Time: 0:04:36.464050, predicting with model: movie_mean_user_habit_std\n",
      "Time: 0:05:49.708299, Saving results of movie_mean_user_habit_std...\n",
      "\n",
      "Time: 0:05:54.426676, predicting with model: movie_median_user_habit_std\n",
      "Time: 0:07:07.490511, Saving results of movie_median_user_habit_std...\n",
      "\n",
      "Time: 0:07:12.194513, predicting with model: movie_mean_user_habit\n",
      "Time: 0:09:05.243197, Saving results of movie_mean_user_habit...\n",
      "\n",
      "Time: 0:09:09.980634, predicting with model: movie_median_user_habit\n",
      "Time: 0:11:01.497086, Saving results of movie_median_user_habit...\n",
      "\n",
      "Predicting using algo: <function surprise_algo at 0x7f906d40f378>, model: surprise...\n",
      "Time: 0:11:06.255543, predicting with model: surprise_svd\n",
      "[prepare_surprise_data] Saving to surprise_train.csv, surprise_test.csv...\n",
      "Start prediction...\n",
      "Postprocessing predictions...\n",
      "Time: 0:19:52.366732, Saving results of surprise_svd...\n",
      "\n",
      "Time: 0:19:56.417532, predicting with model: surprise_knn\n",
      "[prepare_surprise_data] Saving to surprise_train.csv, surprise_test.csv...\n",
      "Start prediction...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Postprocessing predictions...\n",
      "Time: 0:26:24.319755, Saving results of surprise_knn...\n",
      "\n",
      "Predicting using algo: <function spotlight_algo at 0x7f906d40fe18>, model: spotlight...\n",
      "Time: 0:26:28.344275, predicting with model: spotlight\n",
      "Epoch 0: loss 10.23887618457094\n",
      "Epoch 1: loss 1.4105807440651141\n",
      "Epoch 2: loss 1.0329791089668126\n",
      "Epoch 3: loss 1.0058942099222157\n",
      "Epoch 4: loss 1.0018629024940349\n",
      "Epoch 5: loss 1.000598978145893\n",
      "Epoch 6: loss 1.0002640035034212\n",
      "Epoch 7: loss 0.9998772817235658\n",
      "Epoch 8: loss 0.9996544700075409\n",
      "Epoch 9: loss 0.9992678283530249\n",
      "Epoch 10: loss 0.9990517787696901\n",
      "Epoch 11: loss 0.998759041018152\n",
      "Epoch 12: loss 0.9983357461627124\n",
      "Epoch 13: loss 0.9980267005518448\n",
      "Epoch 14: loss 0.9974926759129558\n",
      "Epoch 15: loss 0.9969043368461497\n",
      "Epoch 16: loss 0.996135332834311\n",
      "Epoch 17: loss 0.9953686251828027\n",
      "Epoch 18: loss 0.9942902634329462\n",
      "Epoch 19: loss 0.992964056625528\n",
      "Epoch 20: loss 0.9912666172865112\n",
      "Epoch 21: loss 0.9893524169195937\n",
      "Epoch 22: loss 0.9869315127358845\n",
      "Epoch 23: loss 0.9841288224983962\n",
      "Epoch 24: loss 0.9808204217986887\n",
      "Epoch 25: loss 0.9773336878259475\n",
      "Epoch 26: loss 0.9733587455210244\n",
      "Epoch 27: loss 0.9691056099960523\n",
      "Epoch 28: loss 0.9644456985412654\n",
      "Epoch 29: loss 0.9594721340158288\n",
      "Epoch 30: loss 0.9543886388862273\n",
      "Epoch 31: loss 0.9487152723526633\n",
      "Epoch 32: loss 0.9427709489373758\n",
      "Epoch 33: loss 0.9362612529104821\n",
      "Epoch 34: loss 0.9293498931474508\n",
      "Epoch 35: loss 0.921839253546726\n",
      "Epoch 36: loss 0.9136937684393697\n",
      "Epoch 37: loss 0.9049619627211497\n",
      "Epoch 38: loss 0.8955771795507617\n",
      "Epoch 39: loss 0.8856069281625976\n",
      "Epoch 40: loss 0.8747428901276416\n",
      "Epoch 41: loss 0.863120934752186\n",
      "Epoch 42: loss 0.8507109545738399\n",
      "Epoch 43: loss 0.8375102420924486\n",
      "Epoch 44: loss 0.8238359358503592\n",
      "Epoch 45: loss 0.8089519555203653\n",
      "Epoch 46: loss 0.7935881500738815\n",
      "Epoch 47: loss 0.7774057998611597\n",
      "Epoch 48: loss 0.7606222258670893\n",
      "Epoch 49: loss 0.743175576780868\n",
      "Time: 1:40:22.190268, Saving results of spotlight...\n",
      "\n",
      "Predicting using algo: <function pyfm_algo at 0x7f901ea6e158>, model: pyfm...\n",
      "Time: 1:40:26.237526, predicting with model: pyfm\n",
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.54272\n",
      "-- Epoch 2\n",
      "Training MSE: 0.51075\n",
      "-- Epoch 3\n",
      "Training MSE: 0.50235\n",
      "-- Epoch 4\n",
      "Training MSE: 0.49773\n",
      "-- Epoch 5\n",
      "Training MSE: 0.49480\n",
      "-- Epoch 6\n",
      "Training MSE: 0.49272\n",
      "-- Epoch 7\n",
      "Training MSE: 0.49111\n",
      "-- Epoch 8\n",
      "Training MSE: 0.48979\n",
      "-- Epoch 9\n",
      "Training MSE: 0.48862\n",
      "-- Epoch 10\n",
      "Training MSE: 0.48750\n",
      "-- Epoch 11\n",
      "Training MSE: 0.48645\n",
      "-- Epoch 12\n",
      "Training MSE: 0.48541\n",
      "-- Epoch 13\n",
      "Training MSE: 0.48434\n",
      "-- Epoch 14\n",
      "Training MSE: 0.48326\n",
      "-- Epoch 15\n",
      "Training MSE: 0.48212\n",
      "-- Epoch 16\n",
      "Training MSE: 0.48090\n",
      "-- Epoch 17\n",
      "Training MSE: 0.47965\n",
      "-- Epoch 18\n",
      "Training MSE: 0.47830\n",
      "-- Epoch 19\n",
      "Training MSE: 0.47688\n",
      "-- Epoch 20\n",
      "Training MSE: 0.47546\n",
      "-- Epoch 21\n",
      "Training MSE: 0.47393\n",
      "-- Epoch 22\n",
      "Training MSE: 0.47245\n",
      "-- Epoch 23\n",
      "Training MSE: 0.47087\n",
      "-- Epoch 24\n",
      "Training MSE: 0.46934\n",
      "-- Epoch 25\n",
      "Training MSE: 0.46781\n",
      "-- Epoch 26\n",
      "Training MSE: 0.46628\n",
      "-- Epoch 27\n",
      "Training MSE: 0.46486\n",
      "-- Epoch 28\n",
      "Training MSE: 0.46345\n",
      "-- Epoch 29\n",
      "Training MSE: 0.46213\n",
      "-- Epoch 30\n",
      "Training MSE: 0.46087\n",
      "-- Epoch 31\n",
      "Training MSE: 0.45966\n",
      "-- Epoch 32\n",
      "Training MSE: 0.45854\n",
      "-- Epoch 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.45744\n",
      "-- Epoch 34\n",
      "Training MSE: 0.45636\n",
      "-- Epoch 35\n",
      "Training MSE: 0.45535\n",
      "-- Epoch 36\n",
      "Training MSE: 0.45439\n",
      "-- Epoch 37\n",
      "Training MSE: 0.45349\n",
      "-- Epoch 38\n",
      "Training MSE: 0.45259\n",
      "-- Epoch 39\n",
      "Training MSE: 0.45173\n",
      "-- Epoch 40\n",
      "Training MSE: 0.45091\n",
      "-- Epoch 41\n",
      "Training MSE: 0.45006\n",
      "-- Epoch 42\n",
      "Training MSE: 0.44932\n",
      "-- Epoch 43\n",
      "Training MSE: 0.44863\n",
      "-- Epoch 44\n",
      "Training MSE: 0.44795\n",
      "-- Epoch 45\n",
      "Training MSE: 0.44730\n",
      "-- Epoch 46\n",
      "Training MSE: 0.44667\n",
      "-- Epoch 47\n",
      "Training MSE: 0.44613\n",
      "-- Epoch 48\n",
      "Training MSE: 0.44561\n",
      "-- Epoch 49\n",
      "Training MSE: 0.44509\n",
      "-- Epoch 50\n",
      "Training MSE: 0.44463\n",
      "-- Epoch 51\n",
      "Training MSE: 0.44416\n",
      "-- Epoch 52\n",
      "Training MSE: 0.44375\n",
      "-- Epoch 53\n",
      "Training MSE: 0.44335\n",
      "-- Epoch 54\n",
      "Training MSE: 0.44299\n",
      "-- Epoch 55\n",
      "Training MSE: 0.44259\n",
      "-- Epoch 56\n",
      "Training MSE: 0.44228\n",
      "-- Epoch 57\n",
      "Training MSE: 0.44193\n",
      "-- Epoch 58\n",
      "Training MSE: 0.44159\n",
      "-- Epoch 59\n",
      "Training MSE: 0.44127\n",
      "-- Epoch 60\n",
      "Training MSE: 0.44097\n",
      "-- Epoch 61\n",
      "Training MSE: 0.44069\n",
      "-- Epoch 62\n",
      "Training MSE: 0.44044\n",
      "-- Epoch 63\n",
      "Training MSE: 0.44014\n",
      "-- Epoch 64\n",
      "Training MSE: 0.43989\n",
      "-- Epoch 65\n",
      "Training MSE: 0.43959\n",
      "-- Epoch 66\n",
      "Training MSE: 0.43931\n",
      "-- Epoch 67\n",
      "Training MSE: 0.43909\n",
      "-- Epoch 68\n",
      "Training MSE: 0.43884\n",
      "-- Epoch 69\n",
      "Training MSE: 0.43862\n",
      "-- Epoch 70\n",
      "Training MSE: 0.43838\n",
      "-- Epoch 71\n",
      "Training MSE: 0.43818\n",
      "-- Epoch 72\n",
      "Training MSE: 0.43798\n",
      "-- Epoch 73\n",
      "Training MSE: 0.43778\n",
      "-- Epoch 74\n",
      "Training MSE: 0.43763\n",
      "-- Epoch 75\n",
      "Training MSE: 0.43742\n",
      "-- Epoch 76\n",
      "Training MSE: 0.43724\n",
      "-- Epoch 77\n",
      "Training MSE: 0.43708\n",
      "-- Epoch 78\n",
      "Training MSE: 0.43687\n",
      "-- Epoch 79\n",
      "Training MSE: 0.43671\n",
      "-- Epoch 80\n",
      "Training MSE: 0.43653\n",
      "-- Epoch 81\n",
      "Training MSE: 0.43642\n",
      "-- Epoch 82\n",
      "Training MSE: 0.43624\n",
      "-- Epoch 83\n",
      "Training MSE: 0.43603\n",
      "-- Epoch 84\n",
      "Training MSE: 0.43590\n",
      "-- Epoch 85\n",
      "Training MSE: 0.43575\n",
      "-- Epoch 86\n",
      "Training MSE: 0.43559\n",
      "-- Epoch 87\n",
      "Training MSE: 0.43538\n",
      "-- Epoch 88\n",
      "Training MSE: 0.43526\n",
      "-- Epoch 89\n",
      "Training MSE: 0.43512\n",
      "-- Epoch 90\n",
      "Training MSE: 0.43493\n",
      "-- Epoch 91\n",
      "Training MSE: 0.43480\n",
      "-- Epoch 92\n",
      "Training MSE: 0.43468\n",
      "-- Epoch 93\n",
      "Training MSE: 0.43448\n",
      "-- Epoch 94\n",
      "Training MSE: 0.43437\n",
      "-- Epoch 95\n",
      "Training MSE: 0.43426\n",
      "-- Epoch 96\n",
      "Training MSE: 0.43411\n",
      "-- Epoch 97\n",
      "Training MSE: 0.43399\n",
      "-- Epoch 98\n",
      "Training MSE: 0.43390\n",
      "-- Epoch 99\n",
      "Training MSE: 0.43377\n",
      "-- Epoch 100\n",
      "Training MSE: 0.43370\n",
      "-- Epoch 101\n",
      "Training MSE: 0.43357\n",
      "-- Epoch 102\n",
      "Training MSE: 0.43351\n",
      "-- Epoch 103\n",
      "Training MSE: 0.43341\n",
      "-- Epoch 104\n",
      "Training MSE: 0.43331\n",
      "-- Epoch 105\n",
      "Training MSE: 0.43325\n",
      "-- Epoch 106\n",
      "Training MSE: 0.43318\n",
      "-- Epoch 107\n",
      "Training MSE: 0.43306\n",
      "-- Epoch 108\n",
      "Training MSE: 0.43298\n",
      "-- Epoch 109\n",
      "Training MSE: 0.43292\n",
      "-- Epoch 110\n",
      "Training MSE: 0.43285\n",
      "-- Epoch 111\n",
      "Training MSE: 0.43273\n",
      "-- Epoch 112\n",
      "Training MSE: 0.43267\n",
      "-- Epoch 113\n",
      "Training MSE: 0.43260\n",
      "-- Epoch 114\n",
      "Training MSE: 0.43252\n",
      "-- Epoch 115\n",
      "Training MSE: 0.43245\n",
      "-- Epoch 116\n",
      "Training MSE: 0.43238\n",
      "-- Epoch 117\n",
      "Training MSE: 0.43229\n",
      "-- Epoch 118\n",
      "Training MSE: 0.43218\n",
      "-- Epoch 119\n",
      "Training MSE: 0.43215\n",
      "-- Epoch 120\n",
      "Training MSE: 0.43206\n",
      "-- Epoch 121\n",
      "Training MSE: 0.43199\n",
      "-- Epoch 122\n",
      "Training MSE: 0.43191\n",
      "-- Epoch 123\n",
      "Training MSE: 0.43183\n",
      "-- Epoch 124\n",
      "Training MSE: 0.43168\n",
      "-- Epoch 125\n",
      "Training MSE: 0.43166\n",
      "-- Epoch 126\n",
      "Training MSE: 0.43157\n",
      "-- Epoch 127\n",
      "Training MSE: 0.43151\n",
      "-- Epoch 128\n",
      "Training MSE: 0.43139\n",
      "-- Epoch 129\n",
      "Training MSE: 0.43132\n",
      "-- Epoch 130\n",
      "Training MSE: 0.43125\n",
      "-- Epoch 131\n",
      "Training MSE: 0.43120\n",
      "-- Epoch 132\n",
      "Training MSE: 0.43109\n",
      "-- Epoch 133\n",
      "Training MSE: 0.43102\n",
      "-- Epoch 134\n",
      "Training MSE: 0.43095\n",
      "-- Epoch 135\n",
      "Training MSE: 0.43088\n",
      "-- Epoch 136\n",
      "Training MSE: 0.43082\n",
      "-- Epoch 137\n",
      "Training MSE: 0.43072\n",
      "-- Epoch 138\n",
      "Training MSE: 0.43066\n",
      "-- Epoch 139\n",
      "Training MSE: 0.43058\n",
      "-- Epoch 140\n",
      "Training MSE: 0.43048\n",
      "-- Epoch 141\n",
      "Training MSE: 0.43049\n",
      "-- Epoch 142\n",
      "Training MSE: 0.43041\n",
      "-- Epoch 143\n",
      "Training MSE: 0.43029\n",
      "-- Epoch 144\n",
      "Training MSE: 0.43025\n",
      "-- Epoch 145\n",
      "Training MSE: 0.43020\n",
      "-- Epoch 146\n",
      "Training MSE: 0.43008\n",
      "-- Epoch 147\n",
      "Training MSE: 0.43004\n",
      "-- Epoch 148\n",
      "Training MSE: 0.43000\n",
      "-- Epoch 149\n",
      "Training MSE: 0.42988\n",
      "-- Epoch 150\n",
      "Training MSE: 0.42984\n",
      "-- Epoch 151\n",
      "Training MSE: 0.42978\n",
      "-- Epoch 152\n",
      "Training MSE: 0.42972\n",
      "-- Epoch 153\n",
      "Training MSE: 0.42963\n",
      "-- Epoch 154\n",
      "Training MSE: 0.42960\n",
      "-- Epoch 155\n",
      "Training MSE: 0.42949\n",
      "-- Epoch 156\n",
      "Training MSE: 0.42941\n",
      "-- Epoch 157\n",
      "Training MSE: 0.42941\n",
      "-- Epoch 158\n",
      "Training MSE: 0.42931\n",
      "-- Epoch 159\n",
      "Training MSE: 0.42922\n",
      "-- Epoch 160\n",
      "Training MSE: 0.42920\n",
      "-- Epoch 161\n",
      "Training MSE: 0.42915\n",
      "-- Epoch 162\n",
      "Training MSE: 0.42909\n",
      "-- Epoch 163\n",
      "Training MSE: 0.42899\n",
      "-- Epoch 164\n",
      "Training MSE: 0.42896\n",
      "-- Epoch 165\n",
      "Training MSE: 0.42886\n",
      "-- Epoch 166\n",
      "Training MSE: 0.42882\n",
      "-- Epoch 167\n",
      "Training MSE: 0.42880\n",
      "-- Epoch 168\n",
      "Training MSE: 0.42868\n",
      "-- Epoch 169\n",
      "Training MSE: 0.42861\n",
      "-- Epoch 170\n",
      "Training MSE: 0.42854\n",
      "-- Epoch 171\n",
      "Training MSE: 0.42852\n",
      "-- Epoch 172\n",
      "Training MSE: 0.42844\n",
      "-- Epoch 173\n",
      "Training MSE: 0.42843\n",
      "-- Epoch 174\n",
      "Training MSE: 0.42834\n",
      "-- Epoch 175\n",
      "Training MSE: 0.42826\n",
      "-- Epoch 176\n",
      "Training MSE: 0.42823\n",
      "-- Epoch 177\n",
      "Training MSE: 0.42820\n",
      "-- Epoch 178\n",
      "Training MSE: 0.42810\n",
      "-- Epoch 179\n",
      "Training MSE: 0.42806\n",
      "-- Epoch 180\n",
      "Training MSE: 0.42806\n",
      "-- Epoch 181\n",
      "Training MSE: 0.42795\n",
      "-- Epoch 182\n",
      "Training MSE: 0.42791\n",
      "-- Epoch 183\n",
      "Training MSE: 0.42786\n",
      "-- Epoch 184\n",
      "Training MSE: 0.42783\n",
      "-- Epoch 185\n",
      "Training MSE: 0.42779\n",
      "-- Epoch 186\n",
      "Training MSE: 0.42774\n",
      "-- Epoch 187\n",
      "Training MSE: 0.42771\n",
      "-- Epoch 188\n",
      "Training MSE: 0.42767\n",
      "-- Epoch 189\n",
      "Training MSE: 0.42762\n",
      "-- Epoch 190\n",
      "Training MSE: 0.42759\n",
      "-- Epoch 191\n",
      "Training MSE: 0.42758\n",
      "-- Epoch 192\n",
      "Training MSE: 0.42747\n",
      "-- Epoch 193\n",
      "Training MSE: 0.42748\n",
      "-- Epoch 194\n",
      "Training MSE: 0.42744\n",
      "-- Epoch 195\n",
      "Training MSE: 0.42737\n",
      "-- Epoch 196\n",
      "Training MSE: 0.42740\n",
      "-- Epoch 197\n",
      "Training MSE: 0.42736\n",
      "-- Epoch 198\n",
      "Training MSE: 0.42736\n",
      "-- Epoch 199\n",
      "Training MSE: 0.42732\n",
      "-- Epoch 200\n",
      "Training MSE: 0.42726\n",
      "Time: 3:01:49.804483, Saving results of pyfm...\n",
      "\n",
      "[load_predictions] files: ['global_mean_predictions(0:00:00.014283).csv', 'global_median_predictions(0:00:04.839709).csv', 'movie_mean_predictions(0:00:30.414437).csv', 'movie_mean_user_habit_predictions(0:09:05.243296).csv', 'movie_mean_user_habit_std_predictions(0:05:49.708456).csv', 'movie_mean_user_std_predictions(0:02:35.547978).csv', 'movie_median_predictions(0:00:36.067237).csv', 'movie_median_user_habit_predictions(0:11:01.497188).csv', 'movie_median_user_habit_std_predictions(0:07:07.490632).csv', 'movie_median_user_std_predictions(0:04:31.718007).csv', 'pyfm_predictions(3:01:49.804699).csv', 'spotlight_predictions(1:40:22.190369).csv', 'surprise_knn_predictions(0:26:24.319883).csv', 'surprise_svd_predictions(0:19:52.366916).csv', 'user_mean_predictions(0:00:14.503957).csv', 'user_median_predictions(0:00:25.515770).csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yawen/anaconda3/envs/ML/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1/16 : global_mean_predictions(0:00:00.014283).csv...\n",
      "Reading 2/16 : global_median_predictions(0:00:04.839709).csv...\n",
      "Reading 3/16 : movie_mean_predictions(0:00:30.414437).csv...\n",
      "Reading 4/16 : movie_mean_user_habit_predictions(0:09:05.243296).csv...\n",
      "Reading 5/16 : movie_mean_user_habit_std_predictions(0:05:49.708456).csv...\n",
      "Reading 6/16 : movie_mean_user_std_predictions(0:02:35.547978).csv...\n",
      "Reading 7/16 : movie_median_predictions(0:00:36.067237).csv...\n",
      "Reading 8/16 : movie_median_user_habit_predictions(0:11:01.497188).csv...\n",
      "Reading 9/16 : movie_median_user_habit_std_predictions(0:07:07.490632).csv...\n",
      "Reading 10/16 : movie_median_user_std_predictions(0:04:31.718007).csv...\n",
      "Reading 11/16 : pyfm_predictions(3:01:49.804699).csv...\n",
      "Reading 12/16 : spotlight_predictions(1:40:22.190369).csv...\n",
      "Reading 13/16 : surprise_knn_predictions(0:26:24.319883).csv...\n",
      "Reading 14/16 : surprise_svd_predictions(0:19:52.366916).csv...\n",
      "Reading 15/16 : user_mean_predictions(0:00:14.503957).csv...\n",
      "Reading 16/16 : user_median_predictions(0:00:25.515770).csv...\n",
      "Finished loading.\n",
      "Stacking 0.039218357737556234 * global_mean...\n",
      "Stacking 0.03834579880156073 * global_median...\n",
      "Stacking -0.0725975690066108 * user_mean...\n",
      "Stacking -0.00789918390882379 * user_median...\n",
      "Stacking -0.007740758638513599 * movie_mean...\n",
      "Stacking 0.05957828523443381 * movie_median...\n",
      "Stacking 0.14060176214789746 * movie_mean_user_std...\n",
      "Stacking 0.16847202307620532 * movie_median_user_std...\n",
      "Stacking -0.13447269055892114 * movie_mean_user_habit_std...\n",
      "Stacking -0.1456809113227612 * movie_median_user_habit_std...\n",
      "Stacking -0.11955677173311868 * movie_mean_user_habit...\n",
      "Stacking -0.05223704160233942 * movie_median_user_habit...\n",
      "Stacking 0.013492358136093105 * surprise_svd...\n",
      "Stacking 0.07331438341412916 * surprise_knn...\n",
      "Stacking 0.5124571545404157 * spotlight...\n",
      "Stacking 0.5034777822960248 * pyfm...\n",
      "Creating submission file...\n"
     ]
    }
   ],
   "source": [
    "%run stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import produce_predict_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading baseline models...\n",
      "1 model families loaded:\n",
      " als: als, ; \n",
      "\n",
      "[load_dataset] Valid: (1176952, 3)\n",
      "[load_dataset] Valid: (1176952, 3)\n",
      "Splitting data for training...\n",
      "[split_dataset] Valid: (1176952, 3)\n",
      "Results of split:    User  Movie  Rating\n",
      "0  4292    161       3\n",
      "1  7913    757       4\n",
      "2  7963    418       2\n",
      "3  8809    168       2\n",
      "4  4814    416       4; \n",
      "    User  Movie  Rating\n",
      "0  1207    877       3\n",
      "1  2337    179       3\n",
      "2  4221    971       4\n",
      "3  2306    148       5\n",
      "4  3092    188       4\n",
      "Predicting using algo: <function als_algo at 0x7f349be65158>, model: als...\n",
      "Time: 0:00:00.000076, predicting with model: als\n",
      "ALS Final training RMSE : 0.8370310419716797\n",
      "[als_algo] prediction:     User  Movie    Rating\n",
      "67     1     68  3.113779\n",
      "83     1     84  4.866766\n",
      "205    1    206  4.665121\n",
      "309    1    310  5.154342\n",
      "471    1    472  4.236025\n",
      "Time: 1:45:59.817836, Saving results of als...\n",
      "\n",
      "Saving ground_truth to ./predict_save/ground_truth_1:46:02.133613.csv\n",
      "[load_dataset] Valid: (1176952, 3)\n",
      "[load_dataset] Valid: (1176952, 3)\n",
      "Predicting using algo: <function als_algo at 0x7f349be65158>, model: als...\n",
      "Time: 0:00:00.000135, predicting with model: als\n",
      "ALS Final training RMSE : 0.9266754968488595\n",
      "[als_algo] prediction:     User  Movie    Rating\n",
      "3      1      4  3.821791\n",
      "7      1      8  3.443690\n",
      "20     1     21  3.113324\n",
      "101    1    102  4.000825\n",
      "126    1    127  3.109752\n",
      "Time: 2:26:01.970920, Saving results of als...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run produce_predict_csv none als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
