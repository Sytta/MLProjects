{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from baseline import *\n",
    "from baseline_helpers import *\n",
    "from surprise_helpers import *\n",
    "from spotlight_helpers import *\n",
    "from pyfm_helpers import *\n",
    "import scipy.optimize as sco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    print(\"Loading models...\")\n",
    "    models_dict = dict(\n",
    "        # Baseline parameters: (train, test)\n",
    "        baseline = dict(\n",
    "            global_mean = baseline_global_mean,\n",
    "            global_median = baseline_global_median,\n",
    "            user_mean = baseline_user_mean,\n",
    "            user_median = baseline_user_median,\n",
    "            movie_mean = baseline_movie_mean,\n",
    "            movie_median = baseline_movie_median,\n",
    "            movie_mean_user_std = movie_mean_user_standardize,\n",
    "            movie_median_user_std = movie_median_user_standardize,\n",
    "            movie_mean_user_habit_std = movie_mean_user_habit_standardize,\n",
    "            movie_median_user_habit_std = movie_median_user_habit_standardize,\n",
    "            movie_mean_user_habit = movie_mean_user_habit,\n",
    "            movie_mdeian_user_habit = movie_median_user_habit,\n",
    "        ),\n",
    "        \n",
    "        # surprise\n",
    "        surprise = dict(\n",
    "            surprise_svd = SVD(n_factors=50, n_epochs=200, lr_bu=1e-9 , lr_qi=1e-5, reg_all=0.01),\n",
    "            surprise_svd_pp = SVDpp(n_factors=50, n_epochs=200, lr_bu=1e-9 , lr_qi=1e-5, reg_all=0.01),\n",
    "            surprise_knn = KNNBaseline(k=100, sim_options={'name': 'pearson_baseline', 'user_based': False}),\n",
    "        ),\n",
    "        # spotlight\n",
    "        spotlight = dict(\n",
    "            spotlight=ExplicitFactorizationModel(loss='regression',\n",
    "                                   embedding_dim=150,  # latent dimensionality\n",
    "                                   n_iter=50,  # number of epochs of training\n",
    "                                   batch_size=256,  # minibatch size\n",
    "                                   l2=1e-5,  # strength of L2 regularization\n",
    "                                   learning_rate=0.0001,\n",
    "                                   use_cuda=torch.cuda.is_available()),\n",
    "        ),\n",
    "        # als\n",
    "        \n",
    "        # pyfm\n",
    "        pyfm = dict(\n",
    "            pyfm=pylibfm.FM(num_factors=42, num_iter=200, verbose=True, \n",
    "                          task=\"regression\", initial_learning_rate=0.01, \n",
    "                          learning_rate_schedule=\"optimal\")\n",
    "        ),\n",
    "        # keras\n",
    "        # MF\n",
    "    )\n",
    "    \n",
    "    model_msg = \"{} model families loaded:\\n \".format(len(list(models_dict.keys())))\n",
    "    for i in list(models_dict.keys()):\n",
    "        model_msg = model_msg + \"{}; \".format(i)\n",
    "    print(model_msg)\n",
    "    return models_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "4 model families loaded:\n",
      " baseline; surprise; spotlight; pyfm; \n"
     ]
    }
   ],
   "source": [
    "models = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': <function baseline_helpers.baseline_algo(train, test, model, training=False)>,\n",
       " 'surprise': <function surprise_helpers.surprise_algo(train, test, algo, verbose=True, training=False)>,\n",
       " 'spotlight': <function spotlight_helpers.spotlight_algo(train, test, model, verbose=True)>,\n",
       " 'pyfm': <function pyfm_helpers.pyfm_algo(train_df, test_df, model)>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_algos():\n",
    "    algo_dict = dict(\n",
    "        baseline = baseline_algo, # baseline_algo(train, test, model)\n",
    "        surprise = surprise_algo, # surprise_algo(train, test, algo, verbose=True, training=False)\n",
    "        spotlight = spotlight_algo, # spotlight_algo(train, test, model, verbose=True)\n",
    "        pyfm = pyfm_algo,\n",
    "    )\n",
    "    return algo_dict\n",
    "load_algos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save(folder = \"./predictions/\"):\n",
    "    # create folder if not existent\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    # load csv\n",
    "    train_df = load_dataset(train_dataset)\n",
    "    test_df = load_dataset(test_dataset)\n",
    "    \n",
    "    # dictionary of the predictions\n",
    "    predictions = dict()\n",
    "        \n",
    "    # load models\n",
    "    models_dict = load_models()\n",
    "    # load algos\n",
    "    algo_dict = load_algos()\n",
    "    t = Timer()\n",
    "    t.start()\n",
    "    for model_family_name, model_family in models_dict.items():\n",
    "        algo = algo_dict[model_family_name]\n",
    "        print(\"Predicting using algo: {}, model: {}...\".format(algo, model_family_name))\n",
    "\n",
    "        for model_name, model in model_family.items():\n",
    "            \n",
    "            prediction = algo(train_df, test_df, model)\n",
    "            print(\"Saving results of {}...\".format(model_name))\n",
    "            prediction.to_csv(\"{}_predictions({}).csv\".format(folder, t.now()))\n",
    "            predictions[model_name] = prediction\n",
    "        \n",
    "    return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "4 model families loaded:\n",
      " baseline; surprise; spotlight; pyfm; \n",
      "Predicting using algo: <function baseline_algo at 0x7f7ddbba2620>, model: baseline...\n",
      "Saving results of global_mean...\n",
      "Saving results of global_median...\n",
      "Saving results of user_mean...\n",
      "Saving results of user_median...\n",
      "Saving results of movie_mean...\n",
      "Saving results of movie_median...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'user_standardize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fc3f90022088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-362c1ac22e34>\u001b[0m in \u001b[0;36mpredict_and_save\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_family\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving results of {}...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}_predictions({}).csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MLProjects/Project2/baseline_helpers.py\u001b[0m in \u001b[0;36mbaseline_algo\u001b[0;34m(train, test, model, training)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbaseline_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/MLProjects/Project2/baseline.py\u001b[0m in \u001b[0;36mmovie_mean_user_standardize\u001b[0;34m(train, test, training)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmovie_mean_user_standardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mstand_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_standardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mstand_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_movie_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstand_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_standardize' is not defined"
     ]
    }
   ],
   "source": [
    "predict_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
