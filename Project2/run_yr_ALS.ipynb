{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import os\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(path):\n",
    "    \"\"\"read text file from path.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return f.read().splitlines()\n",
    "\n",
    "\n",
    "def load_data(path_dataset):\n",
    "    \"\"\"Load data in text format, one rating per line, as in the kaggle competition.\"\"\"\n",
    "    data = read_txt(path_dataset)[1:]\n",
    "    return preprocess_data(data)\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"preprocessing the text data, conversion to numerical array format.\"\"\"\n",
    "    def deal_line(line):\n",
    "        pos, rating = line.split(',')\n",
    "        row, col = pos.split(\"_\")\n",
    "        row = row.replace(\"r\", \"\")\n",
    "        col = col.replace(\"c\", \"\")\n",
    "        return int(row), int(col), float(rating)\n",
    "\n",
    "    def statistics(data):\n",
    "        row = set([line[0] for line in data])\n",
    "        col = set([line[1] for line in data])\n",
    "        return min(row), max(row), min(col), max(col)\n",
    "\n",
    "    # parse each line\n",
    "    data = [deal_line(line) for line in data]\n",
    "\n",
    "    # do statistics on the dataset.\n",
    "    min_row, max_row, min_col, max_col = statistics(data)\n",
    "    print(\"number of users: {}, number of movies: {}\".format(max_row, max_col))\n",
    "\n",
    "    # build rating matrix.\n",
    "    ratings = sp.lil_matrix((max_row, max_col))\n",
    "    for row, col, rating in data:\n",
    "        ratings[row - 1, col - 1] = rating\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def group_by(data, index):\n",
    "    \"\"\"group list of list by a specific index.\"\"\"\n",
    "    sorted_data = sorted(data, key=lambda x: x[index])\n",
    "    groupby_data = groupby(sorted_data, lambda x: x[index])\n",
    "    return groupby_data\n",
    "\n",
    "\n",
    "def build_index_groups(train):\n",
    "    \"\"\"build groups for nnz rows and cols.\"\"\"\n",
    "    # row : items; cols: users\n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "\n",
    "    grouped_nz_train_byrow = group_by(nz_train, index=0) # group by items \n",
    "#     for g, value in grouped_nz_train_byrow:\n",
    "#         print(\"{}, {}\".format(g, list(value))) #value for g=0: (0, 1) (0, 2) (0, 3) index of all the users that rated the item 0\n",
    "    nz_row_colindices = [(g, np.array([v[1] for v in value])) # indices of all the users that rated item g\n",
    "                         for g, value in grouped_nz_train_byrow]\n",
    "    \n",
    "#     print(nz_row_colindices)\n",
    "\n",
    "    grouped_nz_train_bycol = group_by(nz_train, index=1) # group by users\n",
    "    nz_col_rowindices = [(g, np.array([v[0] for v in value])) # indices of all the movies rated by user g\n",
    "                         for g, value in grouped_nz_train_bycol]\n",
    "    return nz_train, nz_row_colindices, nz_col_rowindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_per(ratings):\n",
    "    \"\"\"plot the statistics result on raw rating data.\"\"\"\n",
    "    # do statistics.\n",
    "    num_users_per_movie = np.array((ratings != 0).sum(axis=0)).flatten()\n",
    "    num_movies_per_user = np.array((ratings != 0).sum(axis=1).T).flatten()\n",
    "    return num_users_per_movie, num_movies_per_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_users_per_movie, num_movies_per_user,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all movies and users we keep must have at least min_num_ratings per movie and per user. \n",
    "    \"\"\"\n",
    "#     # set seed\n",
    "#     np.random.seed(988)\n",
    "    \n",
    "    # select movie and user based on the condition.\n",
    "    valid_movies = np.where(num_users_per_movie >= min_num_ratings)[0]\n",
    "    valid_users = np.where(num_movies_per_user >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_users, :][: , valid_movies]  \n",
    "    \n",
    "    # init\n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    \n",
    "    print(\"the shape of original ratings. (# of row, # of col): {}\".format(\n",
    "        ratings.shape))\n",
    "    print(\"the shape of valid ratings. (# of row, # of col): {}\".format(\n",
    "        (num_rows, num_cols)))\n",
    "\n",
    "    nz_users, nz_movies = valid_ratings.nonzero()\n",
    "    \n",
    "    # split the data\n",
    "    for movie in set(nz_movies):\n",
    "        # randomly select a subset of ratings\n",
    "        row, col = valid_ratings[:, movie].nonzero()\n",
    "        selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "        residual = list(set(row) - set(selects))\n",
    "\n",
    "        # add to train set\n",
    "        train[residual, movie] = valid_ratings[residual, movie]\n",
    "        if(p_test > 0):\n",
    "            # add to test set\n",
    "            test[selects, movie] = valid_ratings[selects, movie]\n",
    "    \n",
    "    \n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test\n",
    "\n",
    "def init_MF(train, num_features,weight=1.0):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "\n",
    "    num_user,num_movie = train.shape\n",
    "\n",
    "    movie_features = weight * np.random.rand(num_features,num_movie)\n",
    "    user_features = weight * np.random.rand(num_features,num_user)\n",
    "\n",
    "    user_nnz = train.getnnz(axis=1)\n",
    "    user_sum = train.sum(axis=1)\n",
    "\n",
    "    return movie_features, user_features\n",
    "\n",
    "def compute_error(data, movie_features, user_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    # calculate rmse (we only consider nonzero entries.)\n",
    "    mse = 0\n",
    "    for row,col in nz:\n",
    "        movie = movie_features[:,col]\n",
    "        user = user_features[:,row]\n",
    "        mse += ((data[row,col] - movie.T.dot(user))**2)\n",
    "\n",
    "    rmse = np.sqrt(1.0*mse/len(nz))\n",
    "    return rmse\n",
    "\n",
    "def update_movie_feature(\n",
    "        train, user_features, lambda_movie,\n",
    "        nnz_users_per_movie, nz_movie_userindices):\n",
    "    \"\"\"update movie feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_users_per_movie[movie] * lambda_movie\"\"\"\n",
    "    # update and return movie feature.\n",
    "    num_movies = nnz_users_per_movie.shape[0]\n",
    "    num_features = user_features.shape[0]\n",
    "    lambda_I = lambda_movie * sp.eye(num_features)\n",
    "    updated_movie_features = np.zeros((num_features,num_movies))\n",
    "    \n",
    "    for movie,user in nz_movie_userindices:\n",
    "        M = user_features[:,user]\n",
    "        \n",
    "        V = M @ train[user,movie]\n",
    "        A = M @ M.T + nnz_users_per_movie[movie] * lambda_I\n",
    "        Z_star = np.linalg.solve(A,V)\n",
    "        updated_movie_features[:,movie] = np.copy(Z_star.T)\n",
    "    return updated_movie_features\n",
    "\n",
    "def update_user_feature(\n",
    "        train, movie_features, lambda_user,\n",
    "        nnz_movies_per_user, nz_user_movieindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_users_per_user[user] * lambda_user\"\"\"\n",
    "    # update and return user feature.\n",
    "    num_users = nnz_movies_per_user.shape[0]\n",
    "    num_features = movie_features.shape[0]\n",
    "    lambda_I = lambda_user * sp.eye(num_features)\n",
    "    updated_user_features = np.zeros((num_features,num_users))\n",
    "    \n",
    "    for user,movie in nz_user_movieindices:\n",
    "        M = movie_features[:,movie]\n",
    "        \n",
    "        V = M @ train[user,movie].T\n",
    "        A = M @ M.T + nnz_movies_per_user[user] * lambda_I\n",
    "        W_star = np.linalg.solve(A,V)\n",
    "        updated_user_features[:,user] = np.copy(W_star.T)\n",
    "    return updated_user_features\n",
    "\n",
    "def ALS(train,num_features,lambda_movie,lambda_user,max_weight=1.0,iterations=50):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    stop_criterion = 1e-5\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    it = 0\n",
    " \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    \n",
    "#     nz_row, nz_col = test.nonzero()\n",
    "#     nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    # init ALS\n",
    "    movie_features, user_features = init_MF(train, num_features,max_weight)\n",
    "    \n",
    "    # get the number of non-zero ratings for each movie and user\n",
    "    nnz_users_per_movie,nnz_movies_per_user = train.getnnz(axis=0),train.getnnz(axis=1)\n",
    "    \n",
    "    # group the indices by row or column index\n",
    "    _, nz_user_movieindices, nz_movie_userindices = build_index_groups(train)\n",
    "    \n",
    "    train_rmse = 0\n",
    "    # start ALS\n",
    "    while(it < iterations):\n",
    "        movie_features = update_movie_feature(train, user_features, lambda_movie,\n",
    "                            nnz_users_per_movie, nz_movie_userindices)\n",
    "        \n",
    "        user_features = update_user_feature(train, movie_features, lambda_user,\n",
    "                            nnz_movies_per_user, nz_user_movieindices)\n",
    "        \n",
    "        train_rmse = compute_error(train,movie_features,user_features,nz_train)\n",
    "#         print(\"ALS training RMSE : {err}\".format(err=train_rmse))\n",
    "        error_list.append(train_rmse)\n",
    "        change = np.fabs(error_list[-1] - error_list[-2])\n",
    "        if (change < stop_criterion):\n",
    "            print(\"Converge!\")\n",
    "            break;\n",
    "        it += 1\n",
    "        \n",
    "    print(\"ALS Final training RMSE : {err}\".format(err=train_rmse))\n",
    "    # evaluate the error in test set\n",
    "    \n",
    "#     test_rmse = compute_error(test, movie_features, user_features, nz_test)\n",
    "#     print(\"RMSE on test data after ALS: {}.\".format(test_rmse))   \n",
    "    \n",
    "    return user_features,movie_features\n",
    "\n",
    "def cv_ALS_random_search(train,test=None,seed=988):\n",
    "\n",
    "    movies_range = np.linspace(0.01,1,num=100)\n",
    "    user_range = np.linspace(0.01,1,num=100)\n",
    "    features_num_range = np.linspace(1,60,num=60,dtype=np.int32)\n",
    "    weight_range = np.linspace(1.0,3.0,num=60)\n",
    "    \n",
    "    lambda_movies = np.random.choice(movies_range,60)\n",
    "    lambda_users = np.random.choice(user_range,60)\n",
    "    nb_features = np.random.choice(features_num_range,60)\n",
    "    weights = np.random.choice(weight_range,60)\n",
    "    \n",
    "    # for test\n",
    "#     lambda_movies = [0.01]\n",
    "#     lambda_users = [0.2]\n",
    "#     nb_features = [20]\n",
    "#     weights = [1.0]\n",
    "    \n",
    "    best_weight = -1\n",
    "    best_lambda_user = -1\n",
    "    best_lambda_movie = -1\n",
    "    best_num_feature = -1\n",
    "    best_rmse = 100\n",
    "    \n",
    "    k_fold = 5\n",
    "    \n",
    "    newpath = r'./data' \n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    train_tr_list, test_tr_list = split_for_cv(train,p_test=0.2)\n",
    "    for num_features,weight,lambda_movie,lambda_user in zip(nb_features,weights,lambda_movies,lambda_users):\n",
    "        rmse_list = []\n",
    "        for train_tr,test_tr in zip(train_tr_list, test_tr_list): # 5-fold cv\n",
    "            user_features,movie_features = ALS(train_tr,num_features,lambda_movie,lambda_user,weight)\n",
    "            nz_row, nz_col = test_tr.nonzero()\n",
    "            nz_test = list(zip(nz_row, nz_col))\n",
    "            test_tr_rmse = compute_error(test_tr, movie_features, user_features, nz_test)\n",
    "            print(\"RMSE on test data after ALS: {}.\".format(test_tr_rmse))  \n",
    "#             print(\"test RMSE: {te_rmse}\" .format(te_rmse=test_tr_rmse))\n",
    "            rmse_list.append(test_tr_rmse)\n",
    "        test_rmse = np.mean(rmse_list)\n",
    "        if(test_rmse < best_rmse):\n",
    "            best_rmse = test_rmse\n",
    "            bset_lambda_user = lambda_user\n",
    "            best_lambda_movie = lambda_movie\n",
    "            best_weight = weight\n",
    "            best_num_feature = num_features\n",
    "            best_rmse = test_rmse\n",
    "            print(\"CHANGE=====>best rmse: {},lambda_user :{},lambda_movie:{},weight:{},num_feature:{}\"\\\n",
    "                  .format(best_rmse,bset_lambda_user,best_lambda_movie,best_weight,best_num_feature))\n",
    "            \n",
    "    print(\"=======>>>> FINAL: BEST RMSE: {},lambda_user :{},lambda_movie:{},weight:{},num_feature:{}\"\\\n",
    "                              .format(best_rmse,bset_lambda_user,best_lambda_movie,best_weight,best_num_feature))\n",
    "    \n",
    "    best_param = np.array([best_num_feature,best_weight,best_lambda_movie,bset_lambda_user])\n",
    "#     np.save(\"best_param_random_search.npy\", best_param)\n",
    "    return best_num_feature,best_weight,best_lambda_movie,bset_lambda_user\n",
    "\n",
    "def split_for_cv(train,p_test=0.2,k_fold=5):\n",
    "    # init\n",
    "    num_rows, num_cols = train.shape\n",
    "    nz_users, nz_movies = train.nonzero()\n",
    "    train_tr_list=[]\n",
    "    test_tr_list = []\n",
    "    # for test\n",
    "#     k_fold = 1\n",
    "    # split the data\n",
    "    for k in range(k_fold):\n",
    "        train_tr = sp.lil_matrix((num_rows, num_cols))\n",
    "        test_tr = sp.lil_matrix((num_rows, num_cols))\n",
    "        for movie in set(nz_movies):\n",
    "            # randomly select a subset of ratings\n",
    "            row, col = train[:, movie].nonzero()\n",
    "            selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "            residual = list(set(row) - set(selects))\n",
    "\n",
    "            # add to train set\n",
    "            train_tr[residual, movie] = train[residual, movie]\n",
    "\n",
    "            # add to test set\n",
    "            test_tr[selects, movie] = train[selects, movie]\n",
    "            \n",
    "        train_tr_list.append(train_tr)\n",
    "        test_tr_list.append(test_tr)\n",
    "        \n",
    "    return train_tr_list, test_tr_list\n",
    "\n",
    "def predict_ALS(num_features=None,lambda_movie=None,lambda_user=None,weight=None,load_File=None):\n",
    "    seed = 988\n",
    "    train_dataset = \"./data/data_train.csv\"\n",
    "    ratings = load_data(train_dataset)\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    num_users_per_movie,num_movies_per_user = get_number_per(ratings)\n",
    "    valid_ratings, train, _= split_data(\n",
    "    ratings, num_users_per_movie, num_movies_per_user, min_num_ratings=0, p_test=0)\n",
    "    \n",
    "    if(load_File==1):\n",
    "        best_param = np.load(\"best_param_random_search.npy\")\n",
    "        num_features = best_param[0]\n",
    "        weight = best_param[1]\n",
    "        lambda_movie = best_param[2]\n",
    "        lambda_user = best_param[3]\n",
    "#     else:\n",
    "#         num_features = 20\n",
    "#         weight = 2.18644068\n",
    "#         lambda_movie = 0.02\n",
    "#         lambda_user = 0.47\n",
    "    user_features,movie_features = ALS(train,num_features,lambda_movie,lambda_user,weight)\n",
    "    predict_labels = user_features.T @ movie_features\n",
    "    predict = np.asarray(predict_labels.T)\n",
    "    movie_user_predict = pd.DataFrame(data=predict)\n",
    "    movie_user_predict.reset_index(inplace=True)\n",
    "    movie_user_predict.rename(columns={\"index\":\"Movie\"},inplace=True)\n",
    "    movie_user_predict_melt = pd.melt(movie_user_predict,id_vars=[\"Movie\"],var_name=\"User\",value_name =\"Rating\")\n",
    "    movie_user_predict_melt[\"Movie\"] = movie_user_predict_melt[\"Movie\"].values +1\n",
    "    movie_user_predict_melt[\"User\"] = movie_user_predict_melt[\"User\"].values +1\n",
    "    \n",
    "    sample = pd.read_csv(\"./data/sampleSubmission.csv\")\n",
    "    movie_user_predict_melt['Id'] = movie_user_predict_melt.apply(lambda x: 'r{}_c{}'.format(int(x.User), int(x.Movie)), axis=1)\n",
    "    prediction = movie_user_predict_melt[movie_user_predict_melt.Id.isin(sample.Id.values)]\n",
    "    prediction = prediction[[\"User\",\"Movie\",\"Rating\"]]\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cross_validation(intest=0,seed=988):\n",
    "    train_dataset = \"./data/data_train.csv\"\n",
    "    ratings = load_data(train_dataset)\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    num_users_per_movie,num_movies_per_user = get_number_per(ratings)\n",
    "    valid_ratings, train, test = split_data(\n",
    "    ratings, num_users_per_movie, num_movies_per_user, min_num_ratings=0, p_test=0.2)\n",
    "    if(intest ==1):\n",
    "        num_features = 20\n",
    "        weight = 1.0\n",
    "        lambda_movie = 0.2\n",
    "        lambda_user = 0.02\n",
    "    else:\n",
    "        num_features,weight,lambda_movie,lambda_user = cv_ALS_random_search(train,test)\n",
    "        \n",
    "    user_features,movie_features = ALS(train,num_features,lambda_movie,lambda_user,weight)\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "    test_rmse = compute_error(test, movie_features, user_features, nz_test)\n",
    "    print(\"RMSE on test data after ALS: {}.\".format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cross_validation and predict_ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 10000, number of movies: 1000\n",
      "the shape of original ratings. (# of row, # of col): (10000, 1000)\n",
      "the shape of valid ratings. (# of row, # of col): (10000, 1000)\n",
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:963742\n",
      "Total number of nonzero elements in test data:213210\n",
      "ALS Final training RMSE : 0.7946960593486011\n",
      "RMSE on test data after ALS: 1.0397257349236775.\n",
      "CHANGE=====>best rmse: 1.0397257349236775,lambda_user :0.2,lambda_movie:0.01,weight:1.0,num_feature:20\n",
      "=======>>>> FINAL: BEST RMSE: 1.0397257349236775,lambda_user :0.2,lambda_movie:0.01,weight:1.0,num_feature:20\n",
      "ALS Final training RMSE : 0.8251958341792075\n",
      "RMSE on test data after ALS: 1.01695386716335.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 1.0, 0.01, 0.2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_cross_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 10000, number of movies: 1000\n",
      "the shape of original ratings. (# of row, # of col): (10000, 1000)\n",
      "the shape of valid ratings. (# of row, # of col): (10000, 1000)\n",
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1176952\n",
      "Total number of nonzero elements in test data:0\n",
      "ALS Final training RMSE : 0.9267277838137825\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_ALS(num_features = 20,weight = 2.18644068,lambda_movie = 0.02,lambda_user = 0.47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ALS_ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als_algo(model,train_df,test_df):\n",
    "    train_users = train_df['User'].values\n",
    "    train_movies = train_df['Movie'].values\n",
    "    \n",
    "    num_rows,num_cols = len(train_df['User'].value_counts()),len(train_df['Movie'].value_counts())\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    for row,col in zip(train_users,train_movies):\n",
    "        train[row-1,col-1] = train_df.loc[(train_df['User']==row) &(train_df['Movie']==col),'Rating'].values[0]\n",
    "    \n",
    "    # use best parameters from tuning\n",
    "    num_features = 20\n",
    "    weight = 2.18644068\n",
    "    lambda_movie = 0.02\n",
    "    lambda_user = 0.47\n",
    "    # ALS\n",
    "    user_features,movie_features = ALS(train,num_features,lambda_movie,lambda_user,weight)\n",
    "    predict_labels = user_features.T @ movie_features\n",
    "    predict = np.asarray(predict_labels.T)\n",
    "    movie_user_predict = pd.DataFrame(data=predict)\n",
    "    movie_user_predict.reset_index(inplace=True)\n",
    "    movie_user_predict.rename(columns={\"index\":\"Movie\"},inplace=True)\n",
    "    movie_user_predict_melt = pd.melt(movie_user_predict,id_vars=[\"Movie\"],var_name=\"User\",value_name =\"Rating\")\n",
    "    movie_user_predict_melt[\"Movie\"] = movie_user_predict_melt[\"Movie\"].values +1\n",
    "    movie_user_predict_melt[\"User\"] = movie_user_predict_melt[\"User\"].values +1\n",
    "    \n",
    "    # match test_df\n",
    "    test_copy = test_df.copy()\n",
    "    test_copy['Id'] = test_copy.apply(lambda x: 'r{}_c{}'.format(int(x.User), int(x.Movie)), axis=1)\n",
    "    movie_user_predict_melt['Id'] = movie_user_predict_melt.apply(lambda x: 'r{}_c{}'.format(int(x.User), int(x.Movie)), axis=1)\n",
    "    prediction = movie_user_predict_melt[movie_user_predict_melt.Id.isin(test_copy.Id.values)]\n",
    "    prediction = prediction[[\"User\",\"Movie\",\"Rating\"]]\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_dataset] Valid: (1176952, 3)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = \"./data/data_train.csv\"\n",
    "train = load_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[split_dataset] Valid: (1176952, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df,test_df = split_dataset(train, p_test=0.5, min_num_ratings = 0, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Final training RMSE : 0.8368785502746782\n"
     ]
    }
   ],
   "source": [
    "prediction = als_algo(\"\",train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>4.146062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1</td>\n",
       "      <td>310</td>\n",
       "      <td>4.500077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>4.273782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>474</td>\n",
       "      <td>3.779509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1</td>\n",
       "      <td>591</td>\n",
       "      <td>4.378495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User  Movie    Rating\n",
       "83     1     84  4.146062\n",
       "309    1    310  4.500077\n",
       "438    1    439  4.273782\n",
       "473    1    474  3.779509\n",
       "590    1    591  4.378495"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = train_df['User'].values\n",
    "train_movies = train_df['Movie'].values\n",
    "test_users = test_df['User'].values\n",
    "test_movies = test_df['Movie'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['User'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5, 237, 789, ...,  71, 700, 317], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3499, 6332, 5418, ..., 9442, 1388, 5072], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_rows, num_cols = ratings.shape\n",
    "num_rows,num_cols = len(train_df['User'].value_counts()),len(train_df['Movie'].value_counts())\n",
    "train = sp.lil_matrix((num_rows, num_cols))\n",
    "test = sp.lil_matrix((num_rows, num_cols))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[(train_df['User']==train_users[0]) &(train_df['Movie']==train_movies[0]),'Rating'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row,col in zip(train_users,train_movies):\n",
    "    train[row-1,col-1] = train_df.loc[(train_df['User']==row) &(train_df['Movie']==col),'Rating'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row,col in zip(test_users,test_movies):\n",
    "    test[row-1,col-1] = test_df.loc[(test_df['User']==row) &(test_df['Movie']==col),'Rating'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Final training RMSE : 0.8360334543913748\n",
      "RMSE on test data after ALS: 1.0114695427600195.\n"
     ]
    }
   ],
   "source": [
    "num_features = 20\n",
    "weight = 2.18644068\n",
    "lambda_movie = 0.02\n",
    "lambda_user = 0.47\n",
    "# ALS\n",
    "user_features,movie_features , _ = ALS(train, test,num_features,lambda_movie,lambda_user,weight)\n",
    "predict_labels = user_features.T @ movie_features\n",
    "predict = np.asarray(predict_labels.T)\n",
    "movie_user_predict = pd.DataFrame(data=predict)\n",
    "movie_user_predict.reset_index(inplace=True)\n",
    "movie_user_predict.rename(columns={\"index\":\"Movie\"},inplace=True)\n",
    "movie_user_predict_melt = pd.melt(movie_user_predict,id_vars=[\"Movie\"],var_name=\"User\",value_name =\"Rating\")\n",
    "movie_user_predict_melt[\"Movie\"] = movie_user_predict_melt[\"Movie\"].values +1\n",
    "movie_user_predict_melt[\"User\"] = movie_user_predict_melt[\"User\"].values +1\n",
    "\n",
    "# match test_df\n",
    "test_copy = test_df.copy()\n",
    "test_copy['Id'] = test_copy.apply(lambda x: 'r{}_c{}'.format(int(x.User), int(x.Movie)), axis=1)\n",
    "movie_user_predict_melt['Id'] = movie_user_predict_melt.apply(lambda x: 'r{}_c{}'.format(int(x.User), int(x.Movie)), axis=1)\n",
    "prediction = movie_user_predict_melt[movie_user_predict_melt.Id.isin(test_copy.Id.values)]\n",
    "prediction = prediction[[\"User\",\"Movie\",\"Rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>4.130396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>3.730428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1</td>\n",
       "      <td>472</td>\n",
       "      <td>2.622833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1</td>\n",
       "      <td>546</td>\n",
       "      <td>3.873518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>1</td>\n",
       "      <td>596</td>\n",
       "      <td>4.399626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User  Movie    Rating\n",
       "67     1     68  4.130396\n",
       "83     1     84  3.730428\n",
       "471    1    472  2.622833\n",
       "545    1    546  3.873518\n",
       "595    1    596  4.399626"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
